{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "今Lessonで学んだことを元に, MNISTのファッション版 (Fashion MNIST, クラス数10) を多層パーセプトロン (MLP) によって分類してみましょう.\n",
    "\n",
    "Fashion MNISTの詳細については以下のリンクを参考にしてください.\n",
    "\n",
    "Fashion MNIST: https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標値\n",
    "Accuracy: 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ルール\n",
    "- **下のセルで指定されている`x_train、y_train`以外の学習データは使わないでください。**\n",
    "- **MLPのアルゴリズム部分の実装はnumpyのみで行ってください** (sklearnやtensorflowなどは使用しないでください)。\n",
    "    - データの前処理部分でsklearnの関数を使う (例えば `sklearn.model_selection.train_test_split`) のは問題ありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出方法\n",
    "- 2つのファイルを提出していただきます。\n",
    "    1. テストデータ (`x_test`) に対する予測ラベルを`submission_pred.csv`として保存し、**Homeworkタブから`chap04`を選択して**提出してください。\n",
    "    2. それに対応するpythonのコードを`submission_code.py`として保存し、**Homeworkタブから`chap04 (code)`を選択して**提出してください。\n",
    "      - セルに書いたコードを.py形式で保存するためには%%writefileコマンドなどを利用してください（writefileコマンドではファイルの保存のみが行われセル内のpythonコード自体は実行されません。そのため、実際にコードを走らせる際にはwritefileコマンドをコメントアウトしてください）。\n",
    "      \n",
    "- なお、採点は1で行い、2はコードの確認用として利用します（成績優秀者はコード内容を公開させていただくかもしれません）。コードの内容を変更した場合は、**1と2の両方を提出し直してください**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価方法\n",
    "- 予測ラベルの`y_test`に対する精度 (Accuracy) で評価します.\n",
    "- 毎日夜24時にテストデータの一部に対する精度でLeader Boardを更新します.\n",
    "- 締切日の夜24時にテストデータ全体に対する精度でLeader Boardを更新します. これを最終的な評価とします."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み\n",
    "- この部分は修正しないでください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.modules['tensorflow'] = None\n",
    "\n",
    "def load_fashionmnist():\n",
    "    # 学習データ\n",
    "    x_train = np.load('../data/x_train.npy')\n",
    "    y_train = np.load('../data/y_train.npy')\n",
    "    \n",
    "    # テストデータ\n",
    "    x_test = np.load('../data/x_test.npy')\n",
    "\n",
    "    x_train = x_train.reshape(-1, 784).astype('float32') / 255\n",
    "    y_train = np.eye(10)[y_train.astype('int32')]\n",
    "    x_test = x_test.reshape(-1, 784).astype('float32') / 255\n",
    "    \n",
    "    return x_train, y_train, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多層パーセプトロンの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submission_code.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submission_code.py\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(7)\n",
    "\n",
    "x_train, y_train, x_test = load_fashionmnist()\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=1000)\n",
    "\n",
    "def np_log(x):\n",
    "    # WRITE ME\n",
    "    return np.log(np.clip(x, 1e-10, x))\n",
    "\n",
    "def relu(x):\n",
    "    # WRITE ME\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def deriv_relu(x):\n",
    "    # WRITE ME\n",
    "    return (x > 0).astype(x.dtype)\n",
    "\n",
    "def softmax(x):\n",
    "    # WRITE ME\n",
    "    x -= x.max(axis=1, keepdims=True)\n",
    "    x_exp = np.exp(x)\n",
    "    return x_exp / np.sum(x_exp, axis=1, keepdims=True)\n",
    "\n",
    "def deriv_softmax(x):\n",
    "    # WRITE ME\n",
    "    return softmax() * (1 - softmax(x))\n",
    "\n",
    "class Dense:\n",
    "    # WRITE ME\n",
    "    def __init__(self, in_dim, out_dim, function, deriv_function):\n",
    "        self.W = np.random.uniform(low=-0.08, high=0.08,\n",
    "                                   size=(in_dim, out_dim)).astype('float64')\n",
    "        self.b = np.zeros(out_dim).astype('float64')\n",
    "        self.function = function\n",
    "        self.deriv_function = deriv_function\n",
    "        \n",
    "        self.x = None\n",
    "        self.u = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "        self.params_idxs = np.cumsum([self.W.size, self.b.size])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.matmul(self.x, self.W) + self.b\n",
    "        return self.function(self.u)\n",
    "\n",
    "    def b_prop(self, delta, W):\n",
    "        self.delta = self.deriv_function(self.u) * np.matmul(delta, W.T)\n",
    "        return self.delta\n",
    "    \n",
    "    def compute_grad(self):\n",
    "        batch_size = self.delta.shape[0]\n",
    "        \n",
    "        self.dW = np.matmul(self.x.T, self.delta) / batch_size\n",
    "        self.db = np.matmul(np.ones(batch_size), self.delta) / batch_size\n",
    "\n",
    "    def get_params(self):\n",
    "        return np.concatenate([self.W.ravel(), self.b], axis=0)\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        _W, _b = np.split(params, self.params_idxs)[:-1]\n",
    "        self.W = _W.reshape(self.W.shape)\n",
    "        self.b = _b\n",
    "    \n",
    "    def get_grads(self):\n",
    "        return np.concatenate([self.dW.ravel(), self.db], axis=0)\n",
    "\n",
    "def f_props(layers, x):\n",
    "    # WRITE ME\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "def b_props(layers, delta):\n",
    "    # WRITE ME\n",
    "    batch_size = delta.shape[0]\n",
    "    \n",
    "    for i, layer in enumerate(layers[::-1]):\n",
    "        if i == 0: # 出力層の場合\n",
    "            layer.delta = delta # y - t\n",
    "            layer.compute_grad() # 勾配の計算\n",
    "        else: # 出力層以外の場合\n",
    "            delta = layer.b_prop(delta, W) # 逆伝播\n",
    "            layer.compute_grad() # 勾配の計算\n",
    "\n",
    "        W = layer.W\n",
    "\n",
    "def update_parameters(layers, eps):\n",
    "    # WRITE ME\n",
    "    for layer in layers:\n",
    "        layer.W -= eps * layer.dW\n",
    "\n",
    "        layer.b -= eps * layer.db\n",
    "\n",
    "# WRITE ME\n",
    "layers = [\n",
    "    Dense(784, 100, relu, deriv_relu),\n",
    "    Dense(100, 100, relu, deriv_relu),\n",
    "    Dense(100, 10, softmax, deriv_softmax)\n",
    "]\n",
    "\n",
    "def train_mnist(x, t, eps):\n",
    "    # WRITE ME\n",
    "    # 順伝播\n",
    "    y = f_props(layers, x)\n",
    "\n",
    "    # 誤差の計算\n",
    "    cost = (- t * np_log(y)).sum(axis=1).mean()\n",
    "    \n",
    "    # 逆伝播\n",
    "    delta = y - t\n",
    "    b_props(layers, delta)\n",
    "\n",
    "    # パラメータの更新\n",
    "    update_parameters(layers, eps)\n",
    "\n",
    "    return cost\n",
    "\n",
    "def valid_mnist(x, t):\n",
    "    # WRITE ME\n",
    "    # 順伝播\n",
    "    y = f_props(layers, x)\n",
    "    \n",
    "    # 誤差の計算\n",
    "    cost = (- t * np_log(y)).sum(axis=1).mean()\n",
    "    \n",
    "    return cost, y\n",
    "\n",
    "for epoch in range(5):\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    # オンライン学習\n",
    "    # WRITE ME\n",
    "    for x, t in zip(x_train, y_train):\n",
    "        cost = train_mnist(x[None, :], t[None, :], eps=0.01)\n",
    "    \n",
    "    cost, y_pred = valid_mnist(x_valid, y_valid)\n",
    "    accuracy = accuracy_score(y_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(epoch + 1, cost, accuracy))\n",
    "\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = y = f_props(layers, x_test)\n",
    "y_test = y_test.argmax(axis=1)\n",
    "\n",
    "submission = pd.Series(y_test, name='label')\n",
    "submission.to_csv('submission_pred.csv', header=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 4 2 5 1 8 5 4 8 2 3 9 2 2 8 9 5 7 9 7 6 6 8 6 1 6 9 7 0 0 5 3 8 6 9 7\n",
      " 9 9 9 5 4 3 8 3 9 5 2 1 1 0 9 1 2 5 0 6 9 4 7 4 0 4 5 1 5 4 2 2 0 7 7 5 1\n",
      " 4 0 4 7 0 9 9 6 7 1 2 3 6 0 6 3 3 2 6 7 4 8 9 0 5 5 1 4 5 5 0 6 0 5 8 9 4\n",
      " 9 1 6 9 1 2 6 2 7 5 7 9 0 3 0 1 5 3 6 4 0 3 9 9 3 4 3 0 4 9 8 2 0 7 4 8 7\n",
      " 1 1 1 5 3 9 2 0 9 6 9 5 2 3 6 2 7 8 7 7 9 0 1 3 2 6 4 4 7 7 0 1 9 4 4 7 4\n",
      " 3 3 2 5 8 0 6 3 0 5 0 0 8 2 9 5 8 9 6 1 1 2 4 8 9 8 1 4 8 4 4 4 7 6 9 3 1\n",
      " 1 9 5 7 2 7 0 7 2 4 7 1 6 4 2 2 7 7 9 8 8 2 7 4 9 4 9 8 9 8 9 1 0 8 9 5 0\n",
      " 6 7 8 3 8 9 4 2 1 8 4 6 5 4 5 6 7 1 9 6 3 4 8 8 1 9 5 4 7 0 7 7 9 8 9 9 7\n",
      " 6 4 8 0 7 8 4 6 3 0 4 0 4 5 8 7 7 3 5 7 3 9 6 8 4 0 8 4 8 8 5 8 8 5 5 6 8\n",
      " 8 1 0 8 2 1 1 0 7 8 8 1 5 5 1 9 4 0 3 8 3 0 9 2 7 1 4 1 9 5 9 9 0 4 5 0 0\n",
      " 9 4 1 2 8 9 6 8 6 0 1 9 3 0 0 0 9 0 7 0 1 4 9 3 3 8 2 3 2 8 3 6 1 4 1 1 5\n",
      " 3 7 8 2 9 6 1 4 8 0 3 0 9 2 8 9 5 1 8 7 1 7 1 5 0 0 5 6 1 9 8 3 1 2 2 0 1\n",
      " 8 9 4 3 1 6 7 0 4 7 3 8 1 1 1 8 3 3 3 7 7 9 5 5 1 0 4 4 8 9 6 5 1 4 6 8 7\n",
      " 0 5 4 8 7 5 8 2 0 7 4 9 6 1 0 1 1 5 7 7 0 9 8 5 4 5 5 9 7 0 4 8 2 3 3 6 5\n",
      " 0 9 0 9 8 3 5 0 3 1 5 2 0 1 9 8 4 1 1 7 6 5 3 4 4 4 9 4 7 4 0 5 7 0 9 5 9\n",
      " 6 3 1 2 7 8 3 4 0 2 7 2 7 4 1 5 1 9 4 3 8 4 0 6 2 4 2 1 0 2 1 2 6 0 0 8 0\n",
      " 0 8 5 3 4 4 4 9 5 1 7 6 4 9 4 9 4 9 8 6 8 0 9 9 2 2 5 4 0 7 5 1 6 0 5 0 4\n",
      " 4 4 9 8 4 8 1 6 2 3 4 8 8 4 0 7 6 0 9 4 4 2 7 2 1 5 3 7 8 4 7 3 9 5 9 7 4\n",
      " 7 7 3 7 4 9 3 4 5 3 7 9 6 9 0 1 1 9 7 0 3 7 0 0 8 4 5 9 9 4 6 1 7 4 7 4 3\n",
      " 2 9 1 1 5 5 5 0 2 6 1 9 4 4 2 0 8 5 1 4 0 8 4 2 9 0 3 9 9 7 5 5 0 6 9 1 2\n",
      " 2 1 1 8 8 8 9 7 5 6 1 1 6 3 5 0 0 9 5 5 9 4 0 5 0 8 6 7 6 0 2 9 0 2 1 0 7\n",
      " 3 6 7 0 1 1 7 7 9 7 3 9 0 3 0 0 8 4 9 9 2 4 4 8 4 5 6 0 5 9 7 3 2 9 7 6 8\n",
      " 5 3 1 1 1 4 4 0 9 7 4 8 4 4 0 8 4 2 5 5 9 4 0 0 6 6 4 1 3 2 1 7 4 9 4 1 9\n",
      " 9 0 1 7 5 2 1 7 0 7 8 9 0 1 0 8 3 0 7 3 9 4 8 4 2 2 8 9 0 4 2 8 3 9 4 7 1\n",
      " 4 9 7 0 4 4 0 2 7 9 8 0 6 5 0 3 4 4 3 1 2 3 3 4 5 3 1 2 4 1 0 4 3 4 0 8 8\n",
      " 9 8 5 3 4 4 7 8 7 0 3 5 9 9 9 7 3 4 4 6 0 9 4 6 2 2 5 0 7 7 8 5 7 8 4 8 2\n",
      " 8 0 5 7 1 7 7 4 1 3 9 0 6 8 2 0 1 1 0 3 1 7 8 0 2 4 0 3 9 9 8 9 8 0 3 0 3\n",
      " 8]\n",
      "[0 1 4 3 5 1 8 5 4 8 6 3 9 2 2 8 7 5 7 9 7 4 6 8 0 1 6 9 7 0 0 5 3 8 6 9 7\n",
      " 9 9 9 5 4 3 8 3 9 7 2 1 1 0 9 1 2 5 6 6 7 2 7 4 0 4 5 1 5 2 2 2 0 7 7 5 1\n",
      " 4 0 2 7 0 9 9 6 7 1 2 1 6 6 6 3 3 2 6 7 4 8 9 6 5 5 1 4 5 5 0 6 6 5 8 9 4\n",
      " 9 1 6 5 1 2 6 2 7 5 7 9 0 3 6 1 5 3 6 4 0 3 9 9 3 4 3 0 3 9 8 2 0 7 2 8 7\n",
      " 1 1 1 5 3 9 2 0 9 4 9 5 4 1 2 2 7 8 7 7 9 0 1 3 2 0 2 4 7 7 0 1 9 4 2 7 2\n",
      " 3 3 2 5 8 0 6 3 0 5 0 0 8 2 9 5 8 9 6 1 1 2 4 8 9 8 1 4 8 4 4 4 7 2 9 3 1\n",
      " 1 7 5 7 2 7 0 7 2 4 7 1 6 2 2 2 7 7 9 8 8 2 7 6 9 4 9 8 9 8 9 1 6 8 9 5 0\n",
      " 6 7 8 3 8 9 4 2 1 8 4 6 5 4 5 6 7 1 9 6 3 2 8 8 1 9 5 4 7 0 7 7 9 8 9 9 7\n",
      " 6 4 8 0 7 8 4 2 3 0 2 0 4 5 8 7 7 3 5 7 3 9 6 8 4 0 8 4 8 8 5 8 8 5 5 6 8\n",
      " 8 1 3 8 2 1 1 6 7 8 8 1 5 5 1 9 4 0 3 8 3 6 9 2 7 1 4 6 9 5 9 9 0 4 5 0 0\n",
      " 9 4 1 2 8 9 6 8 3 0 1 9 3 0 0 6 9 0 7 6 1 4 7 3 3 3 2 3 2 8 3 6 1 4 1 1 5\n",
      " 4 7 8 2 9 6 1 4 8 0 3 0 9 2 8 9 5 1 8 7 1 9 1 5 3 0 5 6 1 9 8 4 1 2 2 0 1\n",
      " 8 9 4 3 1 6 7 0 4 7 3 8 1 1 1 8 3 3 3 7 7 9 5 5 1 0 6 3 8 9 6 5 1 6 6 8 7\n",
      " 0 5 4 8 7 5 8 2 0 7 4 9 6 1 0 1 1 5 7 7 0 7 8 5 6 5 5 9 7 0 4 8 4 3 3 6 5\n",
      " 0 9 6 9 8 3 5 0 3 1 5 2 0 1 9 8 4 1 1 5 6 5 3 6 4 4 9 2 7 4 0 5 7 0 9 5 9\n",
      " 6 3 1 2 7 3 3 4 0 2 7 2 7 4 1 5 1 9 4 3 8 4 0 6 2 4 6 1 3 2 1 2 6 0 0 8 0\n",
      " 3 8 5 3 2 4 2 9 5 1 7 6 4 9 4 9 4 9 8 6 8 0 9 9 6 2 5 4 0 7 5 1 6 6 5 0 4\n",
      " 4 6 5 8 4 8 1 6 4 3 4 8 8 4 6 7 6 6 9 4 4 2 7 2 1 5 4 7 8 4 7 3 5 5 9 7 4\n",
      " 7 7 3 7 2 9 3 0 5 3 7 9 6 9 3 1 1 9 7 0 3 7 0 4 8 4 7 9 9 4 6 1 7 6 9 4 3\n",
      " 2 9 1 1 5 5 5 0 2 4 1 9 4 4 2 0 8 5 1 4 0 8 4 2 9 6 3 9 9 7 5 5 0 6 9 1 2\n",
      " 2 1 1 8 8 8 9 7 5 6 1 1 6 3 5 3 0 9 5 5 9 4 0 5 0 0 6 7 0 3 2 9 0 2 1 3 7\n",
      " 3 6 7 6 1 1 7 7 9 9 3 9 0 3 6 0 8 6 9 9 2 4 2 8 0 5 0 8 5 9 7 3 2 9 7 0 8\n",
      " 5 3 1 1 1 4 4 0 7 7 4 8 4 4 6 8 2 2 5 5 9 2 0 0 6 6 4 1 4 6 1 7 6 9 4 1 7\n",
      " 9 0 1 7 5 2 1 7 0 7 8 9 2 1 0 8 4 0 7 3 7 4 8 4 2 2 8 9 0 4 2 8 3 9 4 7 1\n",
      " 4 9 7 0 4 4 0 2 7 9 8 0 3 5 0 3 2 4 3 1 6 3 3 2 5 3 1 2 2 1 0 2 3 4 6 8 8\n",
      " 9 8 5 3 4 4 7 8 7 0 3 5 9 9 9 7 3 2 4 2 0 9 4 6 2 2 5 0 7 9 8 5 7 8 4 8 2\n",
      " 8 0 5 7 1 7 7 4 1 3 9 0 6 8 2 0 1 1 0 3 1 7 8 0 2 2 6 3 9 9 8 9 8 0 3 3 3\n",
      " 8]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.argmax(axis=1))\n",
    "print(y_valid.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 6 ... 6 9 6]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
