{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6回講義 演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "課題. 畳み込みニューラルネットワーク(Convolutional Neural Networks)の実装と学習\n",
    "    1. MNISTデータセットの読み込み\n",
    "    2. 畳み込みとプーリング in tensorflow\n",
    "        - 2.1. 畳み込み: tf.nn.conv2d\n",
    "        - 2.2. プーリング: tf.nn.max_pool, tf.nn.avg_pool, etc.\n",
    "    2. 畳み込みとプーリング in tensorflow\n",
    "        - 3.1. 畳み込み層\n",
    "        - 3.2. プーリング層\n",
    "        - 3.3.平滑化層（4次元->2次元）\n",
    "        - 3.4. 全結合層\n",
    "    4. 計算グラフ構築 & パラメータの更新設定\n",
    "    5. 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. 畳み込みニューラルネットワーク(Convolutional Neural Networks)の実装と学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==1.8\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/fa/01883fee1cdb4682bbd188edc26da5982c459e681543bb7f99299fca8800/tensorflow_gpu-1.8.0-cp35-cp35m-manylinux1_x86_64.whl (216.3MB)\n",
      "\u001b[K    100% |################################| 216.3MB 6.9kB/s \n",
      "\u001b[?25hCollecting tensorboard<1.9.0,>=1.8.0 (from tensorflow-gpu==1.8)\n",
      "  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |################################| 3.1MB 511kB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): protobuf>=3.4.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): termcolor>=1.1.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): absl-py>=0.1.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): grpcio>=1.8.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): astor>=0.6.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.13.3 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): gast>=0.2.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): werkzeug>=0.11.10 in /usr/local/lib/python3.5/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8)\n",
      "Collecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8)\n",
      "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied (use --upgrade to upgrade): markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8)\n",
      "Collecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8)\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K    100% |################################| 890kB 1.8MB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): setuptools in /usr/lib/python3/dist-packages (from protobuf>=3.4.0->tensorflow-gpu==1.8)\n",
      "Building wheels for collected packages: html5lib\n",
      "  Running setup.py bdist_wheel for html5lib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
      "Successfully built html5lib\n",
      "Installing collected packages: html5lib, bleach, tensorboard, tensorflow-gpu\n",
      "  Found existing installation: bleach 3.1.0\n",
      "    Uninstalling bleach-3.1.0:\n",
      "      Successfully uninstalled bleach-3.1.0\n",
      "  Found existing installation: tensorboard 1.12.2\n",
      "    Uninstalling tensorboard-1.12.2:\n",
      "      Successfully uninstalled tensorboard-1.12.2\n",
      "  Found existing installation: tensorflow-gpu 1.12.0\n",
      "    Uninstalling tensorflow-gpu-1.12.0:\n",
      "      Successfully uninstalled tensorflow-gpu-1.12.0\n",
      "Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorboard-1.8.0 tensorflow-gpu-1.8.0\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow-gpu==1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNISTデータセットの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込みニューラルネットワーク(CNN)ではMNISTを4次元テンソルとして扱います。MNISTは縦と横のサイズが28×28で、チャネル数は1となるので、画像サイズは(バッチサイズ, 28,28, 1)となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, t_train), (x_valid, t_valid) = mnist.load_data()\n",
    "\n",
    "x_train = (x_train.reshape(-1, 28, 28, 1) / 255).astype(np.float32)\n",
    "x_valid = (x_valid.reshape(-1, 28, 28, 1) / 255).astype(np.float32)\n",
    "\n",
    "t_train = np.eye(10)[t_train].astype(np.float32)\n",
    "t_valid = np.eye(10)[t_valid].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 畳み込みとプーリング in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 畳み込み: tf.nn.conv2d [\\[link\\]](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 入力または隠れ層$X_{i, j}^{k}$\n",
    "    - 次元数4$(n,i,j,k)$\n",
    "        - $n$：バッチサイズ\n",
    "        - $i$：入力の行数\n",
    "        - $j$：入力の列数\n",
    "        - $k$：入力のチャネル数\n",
    "- 畳み込みのフィルタ（重み）$W_{i,j}^{k,l}$\n",
    "    - 次元数4$(i,j,k,l)$\n",
    "        - $i$: フィルタの行数\n",
    "        - $j$: フィルタの列数\n",
    "        - $k$: 入力のチャネル数\n",
    "        - $l$: 出力のチャネル数(フィルタ数)\n",
    "    - ストライド：フィルタを適用する位置の間隔\n",
    "    - ゼロパディング：入力の周りに値0の縁を加えます\n",
    "        - 入力のサイズを保つ為、フィルタの縦or横の次元が$F$のときパディング数を$(F-1)/2$とします。\n",
    "- フィルタ後のサイズは、入力の縦or横の次元数$N$、フィルタの縦or横の次元数$F$、ストライドの縦or横の量$S$で決まります。\n",
    "    - $ceil((N-F+1)/S)$ (ceilは整数値に切り上げ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込みの適用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 入力 (4次元)\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "# サンプル画像\n",
    "sample_image = np.array([[1, 1, 1, 0, 0],\n",
    "                         [0, 1, 1, 1, 0],\n",
    "                         [0, 0, 1, 1, 1],\n",
    "                         [0, 0, 1, 1, 0],\n",
    "                         [0, 1, 1, 0, 0]]\n",
    "                       ).astype('float32').reshape(1, 5, 5, 1)  # バッチサイズ x 高さ x 幅 x チャンネル数\n",
    "\n",
    "# フィルタ\n",
    "W = np.array([[1, 0, 1],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 1]]).astype('float32').reshape(3, 3, 1, 1) # 高さ x 幅 x 入力チャンネル数　x 出力チャンネル数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み1\n",
    "\n",
    "- ストライド: (1, 1)\n",
    "- パディング: なし ('VALID')\n",
    "- 出力のサイズ: ceil((5-3+1)/1)=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 3. 4.]\n",
      " [2. 4. 3.]\n",
      " [2. 3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')  # strides: [1, 高さ, 幅, 1]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み2\n",
    "\n",
    "- ストライド: (2, 2)\n",
    "- パディング: なし\n",
    "- 出力のサイズ: ceil((5-3+1)/2)=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 4.]\n",
      " [2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み3\n",
    "- ストライド: (1, 1)\n",
    "- パディング: SAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2. 3. 1. 1.]\n",
      " [1. 4. 3. 4. 1.]\n",
      " [1. 2. 4. 3. 3.]\n",
      " [1. 2. 3. 4. 1.]\n",
      " [0. 2. 2. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込みの演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 入力 (4次元)\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "# サンプル画像\n",
    "sample_image = np.array([[1, 1, 1, 0, 0, 1, 0],\n",
    "                         [0, 1, 0, 1, 0, 1, 1],\n",
    "                         [1, 0, 1, 1, 1, 0, 1],\n",
    "                         [0, 0, 1, 1, 0, 1, 1],\n",
    "                         [1, 1, 1, 1, 0, 0, 1],\n",
    "                         [0, 1, 1, 1, 1, 1, 1],\n",
    "                         [0, 1, 1, 0, 0, 1, 0]]\n",
    "                       ).astype('float32').reshape(1, 7, 7, 1)\n",
    "\n",
    "# フィルタ\n",
    "W = np.array([[1, 0, 1],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 1]]).astype('float32').reshape(3, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み1\n",
    "\n",
    "- ストライド: (1, 1)\n",
    "- パディング: なし ('VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 2. 4. 2. 3.]\n",
      " [1. 4. 2. 5. 2.]\n",
      " [4. 4. 4. 2. 4.]\n",
      " [3. 4. 4. 4. 3.]\n",
      " [4. 4. 3. 3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み2\n",
    "\n",
    "- ストライド: (2, 2)\n",
    "- パディング: なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 4. 3.]\n",
      " [4. 4. 4.]\n",
      " [4. 3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 畳み込み3\n",
    "\n",
    "- ストライド: (1, 1)\n",
    "- パディング: SAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 1. 3. 0. 2. 2. 1.]\n",
      " [1. 5. 2. 4. 2. 3. 2.]\n",
      " [2. 1. 4. 2. 5. 2. 3.]\n",
      " [1. 4. 4. 4. 2. 4. 1.]\n",
      " [2. 3. 4. 4. 4. 3. 3.]\n",
      " [2. 4. 4. 3. 3. 2. 2.]\n",
      " [1. 2. 3. 2. 2. 3. 1.]]\n"
     ]
    }
   ],
   "source": [
    "convoluted_image = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(convoluted_image, feed_dict={x: sample_image}).reshape(7, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. プーリング: tf.nn.max_pool \\[[link\\]](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool), tf.nn.avg_pool \\[[link\\]](https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- プーリングには次の種類があります。\n",
    "    - Max pooling\n",
    "    - Sum pooling\n",
    "    - Mean pooling\n",
    "    - その他Lpプーリングなど\n",
    "- 畳み込みと同様、ストライドやパディングも考えることがあります。\n",
    "- プーリング後のサイズは、入力の縦or横の次元数$N$、ウィンドウの縦or横の次元数$W$、ストライドの縦or横の量$S$で決まります。\n",
    "    - $ceil((N-W+1)/S)$  (ceilは整数値に切り上げ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プーリングの適用例 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 入力\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "sample_image = np.array([[77, 80, 82, 78, 70],\n",
    "                         [83, 78, 80, 83, 82],\n",
    "                         [87, 82, 81, 80, 74],\n",
    "                         [87, 87, 85, 77, 66],\n",
    "                         [84, 79, 77, 78, 76]]\n",
    "                        ).astype(\"float32\").reshape(1, 5, 5, 1) # バッチサイズ x 高さ x 幅 x チャンネル数s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング1\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (2, 2)\n",
    "- プーリング: max\n",
    "- ceil((5 -2+1) / 2) = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83. 83.]\n",
      " [87. 85.]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング2\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (1, 1)\n",
    "- プーリング: max\n",
    "- ceil((5 -2+1) / 1) = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83. 82. 83. 83.]\n",
      " [87. 82. 83. 83.]\n",
      " [87. 87. 85. 80.]\n",
      " [87. 87. 85. 78.]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング3\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (2, 2)\n",
    "- プーリング: mean\n",
    "- ceil((5 -2+1) / 2) = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79.5  80.75]\n",
      " [85.75 80.75]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プーリングの演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 入力\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "sample_image = np.array([[77, 80, 82, 78, 70, 76, 75],\n",
    "                         [83, 78, 78, 73, 82, 82, 85],\n",
    "                         [87, 82, 81, 80, 74, 88, 70],\n",
    "                         [87, 87, 85, 77, 66, 83, 87],\n",
    "                         [81, 83, 77, 79, 66, 83, 87],\n",
    "                         [87, 87, 83, 70, 66, 83, 87],\n",
    "                         [84, 79, 77, 78, 76, 75, 80]]\n",
    "                        ).astype(\"float32\").reshape(1, 7, 7, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング1\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (2, 2)\n",
    "- プーリング: max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83. 82. 82.]\n",
      " [87. 85. 88.]\n",
      " [87. 83. 83.]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング2\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (1, 1)\n",
    "- プーリング: max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83. 82. 82. 82. 82. 85.]\n",
      " [87. 82. 81. 82. 88. 88.]\n",
      " [87. 87. 85. 80. 88. 88.]\n",
      " [87. 87. 85. 79. 83. 87.]\n",
      " [87. 87. 83. 79. 83. 87.]\n",
      " [87. 87. 83. 78. 83. 87.]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### プーリング3\n",
    "\n",
    "- ウィンドウサイズ: (2, 2)\n",
    "- ストライド: (2, 2)\n",
    "- プーリング: mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79.5  77.75 77.5 ]\n",
      " [85.75 80.75 77.75]\n",
      " [84.5  77.25 74.5 ]]\n"
     ]
    }
   ],
   "source": [
    "pooled_image = tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(pooled_image, feed_dict={x: sample_image}).reshape(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 各層クラスの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.  畳み込み層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "活性化関数としてsigmoid関数やtanh関数のような対象な関数を使用する場合は、Xavierの初期化が使われることが多いです。以下の式で表されます。\n",
    "\n",
    "$\\displaystyle U(-\\sqrt{\\frac{6}{n_{\\mathrm{input}} + n_{\\mathrm{output}}}}, \\sqrt{\\frac{6}{n_{\\mathrm{input}} + n_{\\mathrm{output}}}})$\n",
    "\n",
    "$U$: 一様分布、 $ n_{input}$: 入力されるユニット数、$n_{output}$: 出力されるユニット数\n",
    "\n",
    "※ $ n_{input}$は1ニューロンが前層のいくつのニューロンとつながっているかを表します。\n",
    "\n",
    "今回の場合、非対称なReLUを活性化関数として使うので、Heの初期化を使用しています。以下の式で表されます。\n",
    "\n",
    "$\\displaystyle U(-\\sqrt{\\frac{6}{n_{\\mathrm{input}}}}, \\sqrt{\\frac{6}{n_{\\mathrm{input}}}})$\n",
    "\n",
    "$U$: 一様分布、 $ n_{input}$: 入力されるユニット数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv:\n",
    "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
    "        # Heの初期値\n",
    "        fan_in = np.prod(filter_shape[:3]) # filter_shape: (縦の次元数)x(横の次元数)x(入力チャンネル数)x(出力チャンネル数)\n",
    "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/fan_in),\n",
    "                        high=np.sqrt(6/fan_in),\n",
    "                        size=filter_shape\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b') # バイアスはフィルタごとなので, 出力フィルタ数と同じ次元数\n",
    "        self.function = function\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def __call__(self, x):\n",
    "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b\n",
    "        return self.function(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. プーリング層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
    "        self.ksize = ksize\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. 平滑化層（4次元->2次元）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. 全結合層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        # He Initialization\n",
    "        # in_dim: 入力の次元数、out_dim: 出力の次元数\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/in_dim),\n",
    "                        high=np.sqrt(6/in_dim),\n",
    "                        size=(in_dim, out_dim)\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
    "        self.function = function\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.function(tf.matmul(x, self.W) + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 計算グラフ構築 & パラメータの更新設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今Chapterから `tf` の `Optimizer` が使用可能になります。\n",
    "\n",
    "使い方としては、最小化したい `cost` に対して以下のように学習率を指定することで\n",
    "```\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "```\n",
    "勾配降下法によるパラメータ更新のオペレーションを作成することができます。勾配降下法以外にもAdagrad、Adam等色々あるので、詳しくは公式のドキュメント[[link]](https://www.tensorflow.org/api_guides/python/train)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.log(0)によるnanを防ぐ\n",
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "                                                                          # (縦の次元数)x(横の次元数)x(チャネル数)\n",
    "h = Conv((5, 5, 1, 20), tf.nn.relu)(x)           # 28x28x 1 -> 24x24x20\n",
    "h = Pooling((1, 2, 2, 1))(h)                           # 24x24x20 -> 12x12x20\n",
    "h = Conv((5, 5, 20, 50), tf.nn.relu)(h)        # 12x12x20 ->  8x 8x50\n",
    "h = Pooling((1, 2, 2, 1))(h)                           #  8x 8x50 ->  4x 4x50\n",
    "h = Flatten()(h)\n",
    "y = Dense(4*4*50, 10, tf.nn.softmax)(h)\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Valid Cost: 0.228, Valid Accuracy: 0.932\n",
      "EPOCH: 1, Valid Cost: 0.151, Valid Accuracy: 0.958\n",
      "EPOCH: 2, Valid Cost: 0.117, Valid Accuracy: 0.968\n",
      "EPOCH: 3, Valid Cost: 0.101, Valid Accuracy: 0.972\n",
      "EPOCH: 4, Valid Cost: 0.087, Valid Accuracy: 0.975\n",
      "EPOCH: 5, Valid Cost: 0.081, Valid Accuracy: 0.977\n",
      "EPOCH: 6, Valid Cost: 0.076, Valid Accuracy: 0.978\n",
      "EPOCH: 7, Valid Cost: 0.066, Valid Accuracy: 0.982\n",
      "EPOCH: 8, Valid Cost: 0.070, Valid Accuracy: 0.981\n",
      "EPOCH: 9, Valid Cost: 0.070, Valid Accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = x_train.shape[0]//batch_size\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        x_train, t_train = shuffle(x_train, t_train, random_state=random_state)\n",
    "        for batch in range(n_batches):\n",
    "            start = batch * batch_size\n",
    "            end = start + batch_size\n",
    "            sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end]})\n",
    "        y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid})\n",
    "        print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "            epoch,\n",
    "            cost_valid,\n",
    "            accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
