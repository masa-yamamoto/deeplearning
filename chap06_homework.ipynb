{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "\n",
    "CNNを用いて、FashionMNISTの高精度な分類器を実装してみましょう。\n",
    "\n",
    "モデルのレイヤーを変更してみるなどして精度の向上にチャンレンジして下さい。 精度上位者はリーダーボードに載ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標値\n",
    "\n",
    "Accuracy 93%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ルール\n",
    "\n",
    "- 訓練データはx_train、 t_train、テストデータはx_testで与えられます。\n",
    "- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください。\n",
    "- **下のセルで指定されているx_train、t_train以外の学習データは使わないでください。**\n",
    "- Tensorflowを利用して構いません。\n",
    "- ただし、**tf.layersのような高レベルのAPIは使用しないで下さい。**具体的に以下のモジュールは使用しないでください。\n",
    "\n",
    "```\n",
    "tf.app,\n",
    "tf.compat,\n",
    "tf.contrib,\n",
    "tf.estimator,\n",
    "tf.gfile,\n",
    "tf.graph_util,\n",
    "tf.image,\n",
    "tf.initializers,\n",
    "tf.keras,\n",
    "tf.layers,\n",
    "tf.logging,\n",
    "tf.losses,\n",
    "tf.metrics,\n",
    "tf.python_io,\n",
    "tf.resource_loader,\n",
    "tf.saved_model,\n",
    "tf.sets,\n",
    "tf.summary,\n",
    "tf.sysconfig,\n",
    "tf.test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出方法\n",
    "\n",
    "- 2つのファイルを提出していただきます。\n",
    "  - テストデータ (x_test) に対する予測ラベルをcsvファイル (ファイル名: submission_pred.csv) で提出してください。\n",
    "  - それに対応するpythonのコードをsubmission_code.pyとして提出してください (%%writefileコマンドなどを利用してください)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価方法\n",
    "\n",
    "- 予測ラベルのt_testに対する精度 (Accuracy) で評価します。\n",
    "- 毎日夜24時にテストデータの一部に対する精度でLeader Boardを更新します。\n",
    "- 締切日の夜24時にテストデータ全体に対する精度でLeader Boardを更新します。これを最終的な評価とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み\n",
    "\n",
    "- この部分は修正しないでください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): tensorflow-gpu==1.8 in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.13.3 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): protobuf>=3.4.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): termcolor>=1.1.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): absl-py>=0.1.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): grpcio>=1.8.6 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): gast>=0.2.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): astor>=0.6.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): tensorboard<1.9.0,>=1.8.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): setuptools in /usr/lib/python3/dist-packages (from protobuf>=3.4.0->tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): werkzeug>=0.11.10 in /usr/local/lib/python3.5/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): bleach==1.5.0 in /usr/local/lib/python3.5/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8)\n",
      "Requirement already satisfied (use --upgrade to upgrade): html5lib==0.9999999 in /usr/local/lib/python3.5/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8)\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow-gpu==1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrequired modules are already deleted (Skipped).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    del [\n",
    "        tf.app,\n",
    "        tf.compat,\n",
    "        tf.contrib,\n",
    "        tf.estimator,\n",
    "        tf.gfile,\n",
    "        tf.graph_util,\n",
    "        tf.image,\n",
    "        tf.initializers,\n",
    "        tf.keras,\n",
    "        tf.layers,\n",
    "        tf.logging,\n",
    "        tf.losses,\n",
    "        tf.metrics,\n",
    "        tf.python_io,\n",
    "        tf.resource_loader,\n",
    "        tf.saved_model,\n",
    "        tf.sets,\n",
    "        tf.summary,\n",
    "        tf.sysconfig,\n",
    "        tf.test\n",
    "    ]\n",
    "    \n",
    "except AttributeError:\n",
    "    print('Unrequired modules are already deleted (Skipped).')\n",
    "\n",
    "def load_mnist():\n",
    "\n",
    "    # 学習データ\n",
    "    x_train = np.load('/root/userspace/public/chap06/data/x_train.npy')\n",
    "    t_train = np.load('/root/userspace/public/chap06/data/t_train.npy')\n",
    "    \n",
    "    # テストデータ\n",
    "    x_test = np.load('/root/userspace/public/chap06/data/x_test.npy')\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "    t_train = np.eye(10)[t_train.astype('int32').flatten()]\n",
    "\n",
    "    return (x_train, x_test, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込みニューラルネットワーク(CNN)の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /root/userspace/chap06/materials/submission_code.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /root/userspace/chap06/materials/submission_code.py\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 8\n",
    "\n",
    "### レイヤー定義 ###\n",
    "\n",
    "class Conv:\n",
    "    # WRITE ME\n",
    "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
    "        # Heの初期値\n",
    "        fan_in = np.prod(filter_shape[:3]) # filter_shape: (縦の次元数)x(横の次元数)x(入力チャンネル数)x(出力チャンネル数)\n",
    "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/fan_in),\n",
    "                        high=np.sqrt(6/fan_in),\n",
    "                        size=filter_shape\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b') # バイアスはフィルタごとなので, 出力フィルタ数と同じ次元数\n",
    "        self.function = function\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def __call__(self, x):\n",
    "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b\n",
    "        return self.function(u)    \n",
    "    \n",
    "class Pooling:\n",
    "    # WRITE ME\n",
    "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
    "        self.ksize = ksize\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return tf.nn.avg_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding) #maxからaverageに変更\n",
    "    \n",
    "class Flatten:\n",
    "    # WRITE ME\n",
    "    def __call__(self, x):\n",
    "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
    "    \n",
    "class Dense:\n",
    "    # WRITE ME\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        # He Initialization\n",
    "        # in_dim: 入力の次元数、out_dim: 出力の次元数\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/in_dim),\n",
    "                        high=np.sqrt(6/in_dim),\n",
    "                        size=(in_dim, out_dim)\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
    "        self.function = function\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.function(tf.matmul(x, self.W) + self.b)\n",
    "    \n",
    "def tf_log(x):\n",
    "    # WRITE ME\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
    "    \n",
    "### ネットワーク ###\n",
    "\n",
    "x_train, x_test, t_train = load_mnist()\n",
    "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# WRITE ME 計算グラフの構築\n",
    "                                             # (縦の次元数)x(横の次元数)x(チャネル数)\n",
    "# h = Conv((5, 5, 1, 20), tf.nn.relu)(x)           # 28x28x 1 -> 24x24x20\n",
    "# h = Pooling((1, 2, 2, 1))(h)                           # 24x24x20 -> 12x12x20\n",
    "# h = Conv((5, 5, 20, 50), tf.nn.relu)(h)        # 12x12x20 ->  8x 8x50\n",
    "# h = Pooling((1, 2, 2, 1))(h)                           #  8x 8x50 ->  4x 4x50\n",
    "# h = Flatten()(h)\n",
    "# y = Dense(4*4*50, 10, tf.nn.softmax)(h)\n",
    "\n",
    "#上に代わってこちらを追加\n",
    "# layers = [\n",
    "#     Conv((5, 5, 1, 20), tf.nn.relu),\n",
    "#     Pooling((1, 2, 2, 1)),\n",
    "#     Conv((5, 5, 20, 50), tf.nn.relu),\n",
    "#     Pooling((1, 2, 2, 1)),\n",
    "#     Flatten(),\n",
    "#     Dense(4*4*50, 10, tf.nn.softmax)\n",
    "# ]\n",
    "#試し用\n",
    "layers = [\n",
    "    Conv((5, 5, 1, 20), tf.nn.relu, padding='VALID'),\n",
    "    Conv((5, 5, 20, 20), tf.nn.relu, padding='SAME'),\n",
    "    Pooling((1, 2, 2, 1)),\n",
    "    Conv((5, 5, 20, 50), tf.nn.relu, padding='VALID'),\n",
    "    Pooling((1, 2, 2, 1)),\n",
    "    Flatten(),\n",
    "    Dense(4*4*50, 10, tf.nn.softmax)\n",
    "]\n",
    "\n",
    "def f_props(layers, h):\n",
    "    for layer in layers:\n",
    "        h = layer(h)\n",
    "    return h\n",
    "y = f_props(layers, x)\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))\n",
    "train = tf.train.AdamOptimizer(0.001).minimize(cost) #optimizerはGradientDescentから適宜変える\n",
    "\n",
    "### 学習 ###\n",
    "\n",
    "n_epochs = 25\n",
    "batch_size = 100\n",
    "n_batches = x_train.shape[0]//batch_size\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "    # WRITE ME\n",
    "sess = tf.Session() #error回避のためこっちに変えた。\n",
    "sess.run(init)\n",
    "for epoch in range(n_epochs):\n",
    "    x_train, t_train = shuffle(x_train, t_train, random_state=random_state)\n",
    "    for batch in range(n_batches):\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "        sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end]})\n",
    "    y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid})\n",
    "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "        epoch,\n",
    "        cost_valid,\n",
    "        accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    ))\n",
    "    \n",
    "# WRITE ME\n",
    "y_pred = sess.run(y, feed_dict={x: x_test})\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "print(y_pred)\n",
    "\n",
    "submission = pd.Series(y_pred, name='label')\n",
    "submission.to_csv('/root/userspace/chap06/materials/submission_pred.csv', header=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
