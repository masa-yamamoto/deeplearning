{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "\n",
    "今Lessonで学んだことに工夫を加えて、CNNでより高精度なCIFAR10の分類器を実装してみましょう。精度上位者はリーダーボードに載ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標値\n",
    "\n",
    "Accuracy 78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ルール\n",
    "\n",
    "- 訓練データはx_train、 t_train、テストデータはx_testで与えられます。\n",
    "- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください。\n",
    "- **下のセルで指定されているx_train、t_train以外の学習データは使わないでください。**\n",
    "- ネットワークの形などは特に制限を設けません。\n",
    "- 高レベルのAPI(tf.layers)を利用しても構いません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出方法\n",
    "\n",
    "- 2つのファイルを提出していただきます。\n",
    "  - テストデータ (x_test) に対する予測ラベルをcsvファイル (ファイル名: submission_pred.csv) で提出してください。\n",
    "  - それに対応するpythonのコードをsubmission_code.pyとして提出してください (%%writefileコマンドなどを利用してください)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価方法\n",
    "\n",
    "- 予測ラベルのt_testに対する精度 (Accuracy) で評価します。\n",
    "- 毎日夜24時にテストデータの一部に対する精度でLeader Boardを更新します。\n",
    "- 締切日の夜24時にテストデータ全体に対する精度でLeader Boardを更新します。これを最終的な評価とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み\n",
    "\n",
    "- この部分は修正しないでください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_cifar10():\n",
    "    \n",
    "    # 学習データ\n",
    "    x_train = np.load('/root/userspace/public/chap07/data/x_train.npy')\n",
    "    t_train = np.load('/root/userspace/public/chap07/data/t_train.npy')\n",
    "\n",
    "    # テストデータ\n",
    "    x_test = np.load('/root/userspace/public/chap07/data/x_test.npy')\n",
    "    \n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    \n",
    "    t_train = np.eye(10)[t_train.astype('int32').flatten()]\n",
    "    \n",
    "    return (x_train, x_test, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm:\n",
    "    def __init__(self, shape, epsilon=np.float32(1e-5)):\n",
    "        self.gamma = tf.Variable(np.ones(shape, dtype='float32'), name='gamma')\n",
    "        self.beta  = tf.Variable(np.zeros(shape, dtype='float32'), name='beta')\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def __call__(self, x):\n",
    "        mean, var = tf.nn.moments(x, axes=(0,1,2), keep_dims=True)\n",
    "        std = tf.sqrt(var + self.epsilon)\n",
    "        x_normalized = (x - mean) / std\n",
    "        return self.gamma * x_normalized + self.beta\n",
    "    \n",
    "class Conv:\n",
    "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
    "        fan_in = np.prod(filter_shape[:3])\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/fan_in),\n",
    "                        high=np.sqrt(6/fan_in),\n",
    "                        size=filter_shape\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b') # バイアスはフィルタごと\n",
    "        self.function = function\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def __call__(self, x):\n",
    "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b\n",
    "        return self.function(u)\n",
    "    \n",
    "class Pooling:\n",
    "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
    "        self.ksize = ksize\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return tf.nn.avg_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding) #maxからavgに変更\n",
    "\n",
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
    "    \n",
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/in_dim),\n",
    "                        high=np.sqrt(6/in_dim),\n",
    "                        size=(in_dim, out_dim)\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
    "        self.function = function\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.function(tf.matmul(x, self.W) + self.b)\n",
    "\n",
    "class Activation:\n",
    "    def __init__(self, function=lambda x: x):\n",
    "        self.function = function\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.function(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込みニューラルネットワーク(CNN)の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Valid Cost: 0.871, Valid Accuracy: 0.711\n",
      "EPOCH: 1, Valid Cost: 0.742, Valid Accuracy: 0.745\n",
      "EPOCH: 2, Valid Cost: 0.656, Valid Accuracy: 0.780\n",
      "EPOCH: 3, Valid Cost: 0.672, Valid Accuracy: 0.778\n",
      "EPOCH: 4, Valid Cost: 0.657, Valid Accuracy: 0.783\n",
      "EPOCH: 5, Valid Cost: 0.628, Valid Accuracy: 0.795\n",
      "EPOCH: 6, Valid Cost: 0.662, Valid Accuracy: 0.796\n",
      "EPOCH: 7, Valid Cost: 0.678, Valid Accuracy: 0.800\n",
      "[7 5 4 ... 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "# %%writefile /root/userspace/chap07/materials/submission_code.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rng = np.random.RandomState(1234) #乱数がfixできてない\n",
    "random_state = 8 #1or8がよさげ\n",
    "\n",
    "def tf_log(x):\n",
    "    # WRITE ME\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
    "\n",
    "### ネットワーク ###\n",
    "tf.reset_default_graph()\n",
    "is_training = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "# WRITE ME \n",
    "# 1.layersのAPIを使用\n",
    "# x = tf.placeholder(shape=[None, 32, 32, 3], dtype=tf.float32)\n",
    "# t = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# h = tf.layers.Conv2D(filters=32, kernel_size= [3, 3])(x) # 32x32x3 -> 30x30x32 # conv2dの初期設定: strides=(1, 1), padding='valid' \n",
    "# h = tf.layers.BatchNormalization()(h, training=is_training)\n",
    "# h = tf.nn.relu(h)\n",
    "# h = tf.layers.MaxPooling2D(pool_size=[2, 2], strides=2)(h) # 30x30x32 -> 15x15x32\n",
    "\n",
    "# h = tf.layers.Conv2D(filters=64, kernel_size= [3, 3])(h) # 15x15x32 -> 13x13x64\n",
    "# h = tf.layers.BatchNormalization()(h, training=is_training)\n",
    "# h = tf.nn.relu(h)\n",
    "# h = tf.layers.MaxPooling2D(pool_size=[2, 2], strides=2)(h) # 13x13x64 -> 6x6x64\n",
    "\n",
    "# h = tf.layers.Conv2D(filters=128, kernel_size= [3, 3])(h) # 6x6x64 -> 4x4x128\n",
    "# h = tf.layers.BatchNormalization()(h, training=is_training)\n",
    "# h = tf.nn.relu(h)\n",
    "# h = tf.layers.MaxPooling2D(pool_size=[2, 2], strides=2)(h) # 4x4x128 -> 2x2x128\n",
    "\n",
    "# h = tf.layers.Flatten()(h)\n",
    "# h = tf.layers.Dense(units=256, activation=tf.nn.relu)(h)\n",
    "# # WRITE ME\n",
    "# y = tf.layers.Dense(units=10, activation=tf.nn.softmax)(h) #このやりかただと、最後のtestデータに対する出力のやりかたがわからない\n",
    "\n",
    "\n",
    "# 2. API使用せず\n",
    "x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "                                                      # (縦の次元数)x(横の次元数)x(チャネル数)\n",
    "layers = [\n",
    "    Conv((3, 3, 3, 32), padding='VALID'),             # 32x32x3 -> 30x30x32\n",
    "    Conv((3, 3, 32, 32), padding='SAME'),#追加\n",
    "    BatchNorm((30, 30, 32)), #testデータについてはBN必要なくない？\n",
    "    Activation(tf.nn.relu),\n",
    "    Pooling((1, 2, 2, 1)),                        # 30x30x32 -> 15x15x32\n",
    "    Conv((3, 3, 32, 64), padding='VALID'),           # 15x15x32 -> 13x13x64\n",
    "    BatchNorm((13, 13, 64)),\n",
    "    Activation(tf.nn.relu),\n",
    "    Pooling(((1, 2, 2, 1))),                    # 13x13x64 -> 6x6x64\n",
    "    Conv((3, 3, 64, 128), padding='VALID'),          # 6x6x64 -> 4x4x128\n",
    "    BatchNorm((4, 4, 128)),\n",
    "    Activation(tf.nn.relu),\n",
    "    Pooling((1, 2, 2, 1)),                         # 4x4x128 -> 2x2x128\n",
    "    Flatten(),\n",
    "    Dense(2*2*128, 256, tf.nn.relu),\n",
    "    Dense(256, 10, tf.nn.softmax)\n",
    "]\n",
    "def f_props(layers, h):\n",
    "    for layer in layers:\n",
    "        h = layer(h)\n",
    "    return h\n",
    "y = f_props(layers, x)\n",
    "\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(0.002).minimize(cost) #0.1から適宜変更\n",
    "\n",
    "### 前処理 ###\n",
    "def gcn(x):\n",
    "    # WRITE ME\n",
    "    mean = np.mean(x, axis=(1, 2, 3), keepdims=True)\n",
    "    std = np.std(x, axis=(1, 2, 3), keepdims=True)\n",
    "    return (x - mean)/std\n",
    "\n",
    "class ZCAWhitening:\n",
    "    # WRITE ME\n",
    "    def __init__(self, epsilon=1e-4):\n",
    "        self.epsilon = epsilon\n",
    "        self.mean = None\n",
    "        self.ZCA_matrix = None\n",
    "\n",
    "    def fit(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.mean = np.mean(x, axis=0)\n",
    "        x -= self.mean\n",
    "        cov_matrix = np.dot(x.T, x) / x.shape[0]\n",
    "        A, d, _ = np.linalg.svd(cov_matrix)\n",
    "        self.ZCA_matrix = np.dot(np.dot(A, np.diag(1. / np.sqrt(d + self.epsilon))), A.T)\n",
    "\n",
    "    def transform(self, x):\n",
    "        shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x -= self.mean\n",
    "        x = np.dot(x, self.ZCA_matrix.T)\n",
    "        return x.reshape(shape)    \n",
    "    \n",
    "x_train, x_test, t_train = load_cifar10()\n",
    "\n",
    "# #追加\n",
    "# padded = np.pad(x_train, ((0, 0), (4, 4), (4, 4), (0, 0)), mode='constant')\n",
    "# crops = rng.randint(8, size=(len(x_train), 2))\n",
    "# x_train_cropped = [padded[i, c[0]:(c[0]+32), c[1]:(c[1]+32), :] for i, c in enumerate(crops)]\n",
    "# x_train_cropped = np.array(x_train_cropped)\n",
    "# x_train = np.dstack([x_train, x_train_cropped]) #データセットの結合方法がわからない\n",
    "# t_train = np.dstack([t_train, t_train])\n",
    "# #\n",
    "\n",
    "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
    "zca = ZCAWhitening()\n",
    "zca.fit(x_train)\n",
    "x_train_zca = zca.transform(gcn(x_train))\n",
    "t_train_zca = t_train[:]\n",
    "x_valid_zca = zca.transform(gcn(x_valid))\n",
    "t_valid_zca = t_valid[:]\n",
    "x_test_zca = zca.transform(gcn(x_test))\n",
    "\n",
    "### 学習 ###\n",
    "n_epochs = 8 #10だとcostが再上昇してしまう？\n",
    "batch_size = 100\n",
    "n_batches = x_train.shape[0]//batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # WRITE ME \n",
    "    #1に対応\n",
    "#     x_train_zca, t_train_zca = shuffle(x_train_zca, t_train_zca, random_state=random_state)\n",
    "#     for batch in range(n_batches):\n",
    "#         start = batch * batch_size\n",
    "#         end = start + batch_size\n",
    "#         sess.run(optimizer, feed_dict={x: x_train_zca[start:end], t: t_train_zca[start:end], is_training: True})\n",
    "#     y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid_zca, t: t_valid_zca, is_training: False})\n",
    "#     print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "#         epoch,\n",
    "#         cost_valid,\n",
    "#         accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "#     ))\n",
    "    #2に対応\n",
    "    x_train_zca, t_train_zca = shuffle(x_train_zca, t_train_zca, random_state=random_state)\n",
    "    for batch in range(n_batches):\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "        sess.run(optimizer, feed_dict={x: x_train_zca[start:end], t: t_train_zca[start:end]})\n",
    "    y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid_zca, t: t_valid_zca})\n",
    "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "        epoch,\n",
    "        cost_valid,\n",
    "        accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    ))\n",
    "\n",
    "\n",
    "# WRITE ME\n",
    "y_pred = sess.run(y, feed_dict={x: x_test_zca})\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "print(y_pred)\n",
    "\n",
    "submission = pd.Series(y_pred, name='label')\n",
    "submission.to_csv('/root/userspace/chap07/materials/submission_pred.csv', header=True, index_label='id') #/chap07/materials/を追加\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
