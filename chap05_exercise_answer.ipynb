{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4回講義 演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/root/userspace/public/chap05/materials')\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_seed = 34\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "tf.set_random_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "課題. TensorFlowを学ぶ\n",
    "1. TensorFlow概観\n",
    "2. TensorFlow基礎\n",
    "    - 2.1. `Placeholder`・`Variable`\n",
    "    - 2.2. 行列・テンソル\n",
    "    - 2.3. 数学\n",
    "    - 2.4. 制御構文\n",
    "    - 2.5. 勾配 (微分) の計算\n",
    "    - 2.6. 変数の値の更新\n",
    "3. TensorFlow応用\n",
    "    - 3.1. TensorBoardによるグラフの表示\n",
    "    - 3.2. グラフの管理と整理\n",
    "    - 3.3. モデルの保存・読み込み\n",
    "    - 3.4. メモリの管理\n",
    "    - 3.5. `tf.data.Dataset`の利用\n",
    "4. TensorFlowによるニューラルネットワークの実装\n",
    "    - 4.1. Optimizer\n",
    "    - 4.2. 正則化 (重み減衰)\n",
    "    - 4.3. Dropout\n",
    "    - 4.4. MLP (`tf.data.Dataset`を使用しない版)\n",
    "    - 4.5. MLP (`tf.data.Dataset`を使用する版)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. TensorFlowを学ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TensorFlow概観"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`では、基本的に以下の流れで機械学習モデルを構築していきます。\n",
    "\n",
    "1. `Placeholder`と`Variable`の設定\n",
    "2. グラフの構築\n",
    "3. 誤差関数の設定\n",
    "4. 重みの更新ルールの設定\n",
    "5. `tf.Session()`を開始して学習\n",
    "6. 予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下にロジスティック回帰 (OR) の例を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ (OR)\n",
    "x_data = np.array([[0, 1], [1, 0], [0, 0], [1, 1]]).astype(np.float32)\n",
    "t_data = np.array([[1], [1], [0], [1]]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 100, Train Cost, 0.156\n",
      "EPOCH: 200, Train Cost, 0.090\n",
      "EPOCH: 300, Train Cost, 0.062\n",
      "EPOCH: 400, Train Cost, 0.047\n",
      "EPOCH: 500, Train Cost, 0.038\n",
      "EPOCH: 600, Train Cost, 0.032\n",
      "EPOCH: 700, Train Cost, 0.027\n",
      "EPOCH: 800, Train Cost, 0.024\n",
      "EPOCH: 900, Train Cost, 0.021\n",
      "EPOCH: 1000, Train Cost, 0.019\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9835751 ],\n",
       "       [0.9835755 ],\n",
       "       [0.04120123],\n",
       "       [0.99998796]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1. Placeholder・Variableの設定\n",
    "## Placeholder: データを流し込む変数. データ毎に変わる\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='x')\n",
    "t = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='t')\n",
    "\n",
    "## Variable: 変数 (重み). データ間で共有される\n",
    "W = tf.Variable(tf.random_uniform(shape=(2, 1), minval=-0.08, maxval=0.08, dtype=tf.float32), name='W')\n",
    "b = tf.Variable(tf.zeros(shape=(1), dtype=tf.float32), name='b')\n",
    "\n",
    "# Step 2. グラフの構築\n",
    "y = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "# Step 3. 誤差関数の設定\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf.log(y) + (1 - t) * tf.log(1 - y), axis=1))\n",
    "\n",
    "# Step 4. 重みの更新ルールの設定\n",
    "gW, gb = tf.gradients(cost, [W, b]) # 勾配の計算\n",
    "updates = [\n",
    "    W.assign_sub(0.5 * gW), # 勾配降下法\n",
    "    b.assign_sub(0.5 * gb)\n",
    "]\n",
    "train = tf.group(*updates)\n",
    "\n",
    "# Step 5. tf.Session()を開始して学習\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 重み (Variable) の初期化\n",
    "for epoch in range(1000):\n",
    "    cost_, _ = sess.run([cost, train], feed_dict={x: x_data, t: t_data})\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('EPOCH: {}, Train Cost, {:.3f}'.format(epoch + 1, cost_))\n",
    "\n",
    "# Step 6. 予測\n",
    "print()\n",
    "y_pred = sess.run(y, feed_dict={x: x_data})\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. `Placeholder`・`Variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfには2種類の変数 (のようなもの) があります。それぞれ以下のように使い分けます。\n",
    "\n",
    "- `tf.placeholder`: データ間で値が共有されない変数 (入力の`x`、正解ラベルの `t` などに使用)\n",
    "- `tf.Variable` : データ間で値が共有される変数 (重みの `W`、`b` など更新されるものに使用）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. `tf.placeholder`\n",
    "\n",
    "データを流し込む入り口として使います。\n",
    "- 変数の型 (`tf.int32`、`tf.float32`) を指定する必要があります。\n",
    "- 実行時にはデータを`feed_dict`で渡す必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "y = x**2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y, feed_dict={x: 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shapeが決まっている場合はそれをリストで指定することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.94555587e-02 5.58484495e-01 2.43727374e+00 2.15530962e-01]\n",
      " [1.23947896e-01 1.64222145e+00 8.36940557e-02 9.60455894e-01]\n",
      " [2.28411570e-01 2.03236982e-01 5.66171110e-01 2.60683537e-01]\n",
      " [4.98086065e-01 1.80045128e-01 5.38992546e-02 3.29473495e+00]\n",
      " [4.38797522e+00 1.07320511e+00 2.05675960e+00 7.74112120e-02]\n",
      " [3.54197435e-03 1.71168077e+00 1.65457277e-06 1.59023929e+00]\n",
      " [3.47166322e-02 2.04469323e+00 6.25842333e-01 8.86486322e-02]\n",
      " [9.25347030e-01 1.14584315e+00 1.45315349e+00 4.14775521e-01]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 4))\n",
    "\n",
    "y = x**2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y, feed_dict={x: np.random.randn(8, 4)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. `tf.Variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "値がデータ間で共有されるので、まず初期値を与える必要があります。\n",
    "\n",
    "- 全ての変数を初期化する場合は`tf.global_variables_initializer()`を使います。\n",
    "- 個別に変数を初期化する場合は`tf.variables_initializer()`を使い、引数に初期化したい変数をリストで渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(1.0, name='w')\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#     sess.run(tf.variables_initializer([w, b])) # こちらでも可\n",
    "    \n",
    "    print(w.eval()) # print(sess.run(w))でも同じです\n",
    "    print(b.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = tf.Variable(0.0)\n",
    "# b = tf.Variable(1.0)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.variables_initializer([w]))\n",
    "#     print(w.eval()) \n",
    "#     print(b.eval()) # 初期化していないので、エラーが出ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 行列・テンソル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. 生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的な行列は、NumPyと同様の関数を使って作ることが可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tf.constant:\n",
      "9\n",
      "\n",
      "# tf.ones:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "# tf.zeros:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "# tf.fill:\n",
      "[[99 99 99]\n",
      " [99 99 99]]\n",
      "\n",
      "# tf.eye:\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "# tf.ones_like:\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "# tf.zeros_like:\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# スカラー\n",
    "x_constant = tf.constant(value=9)\n",
    "\n",
    "# 全要素が1の行列\n",
    "x_ones = tf.ones((2, 3))\n",
    "\n",
    "# 全要素が0の行列\n",
    "x_zeros = tf.zeros((2, 3))\n",
    "\n",
    "# 指定した値で満たされた行列\n",
    "x_fill = tf.fill(dims=(2, 3), value=99)\n",
    "\n",
    "# 単位行列\n",
    "x_eye = tf.eye(2)\n",
    "\n",
    "# 渡された変数と同じshapeのtf.ones\n",
    "x_ones_like = tf.ones_like(tensor=x_eye)\n",
    "\n",
    "# 渡された変数と同じshapeのtf.zeros\n",
    "x_zeros_like = tf.zeros_like(tensor=x_eye)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('# tf.constant:')\n",
    "    print(sess.run(x_constant))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.ones:')\n",
    "    print(sess.run(x_ones))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.zeros:')\n",
    "    print(sess.run(x_zeros))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.fill:')\n",
    "    print(sess.run(x_fill))\n",
    "    print()\n",
    "\n",
    "    print('# tf.eye:')\n",
    "    print(sess.run(x_eye))\n",
    "    print()\n",
    "\n",
    "    print('# tf.ones_like:')\n",
    "    print(sess.run(x_ones_like))\n",
    "    print()\n",
    "\n",
    "    print('# tf.zeros_like:')\n",
    "    print(sess.run(x_zeros_like))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらを`Variable`の初期値として利用することも可能です。また代わりにNumPyのarrayを初期値として与えることも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.65697956  0.9696641   0.42789012]\n",
      " [ 0.8992823  -0.42343983 -0.84637344]]\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal((2, 3)), name='w')\n",
    "b = tf.Variable(np.zeros(3), name='b') # tf.zeros(3)でもOK\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(W.eval())\n",
    "    print(b.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. 乱数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般的な乱数は大体揃っています.\n",
    "\n",
    "乱数のシードはグローバルに`tf.set_random_seed`で指定するか、個別にseedオプションで指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# randn:\n",
      "[[ 0.49384186  0.91458374 -0.63111424]\n",
      " [-1.3303034  -1.2144839   0.04439415]]\n",
      "\n",
      "# uniform:\n",
      "[[0.5487499  0.13401854 0.70727   ]\n",
      " [0.04730201 0.74189115 0.40300822]]\n",
      "\n",
      "# bernoulli:\n",
      "[1 0 0 0 1 0 1 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# seedはグラフレベルでリセットされるので, グラフの初期化も必要. (グラフの初期化については後述)\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(34)\n",
    "\n",
    "# 正規分布\n",
    "x_randn = tf.random_normal(shape=(2, 3), mean=0.0, stddev=1.0, seed=34) # seedはseedで指定\n",
    "\n",
    "# 一様分布\n",
    "x_uniform = tf.random_uniform(shape=(2, 3), minval=0, maxval=1)\n",
    "\n",
    "# ベルヌーイ分布\n",
    "x_bernoulli = tf.distributions.Bernoulli(probs=0.5).sample(sample_shape=(10))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('# randn:')\n",
    "    print(sess.run(x_randn))\n",
    "    print()\n",
    "    \n",
    "    print('# uniform:')\n",
    "    print(sess.run(x_uniform))\n",
    "    print()\n",
    "    \n",
    "    print('# bernoulli:')\n",
    "    print(sess.run(x_bernoulli))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3. shapeの確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラフ上の変数のshapeは`tf.shape`で取得することができます。例えば入力データのshapeに合わせて乱数を発生させたいときなどに使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# xのshape:\n",
      "[2 3]\n",
      "\n",
      "# normal 1:\n",
      "[[ 0.6309411   0.6158685  -1.4873706 ]\n",
      " [-0.13940303 -0.36543897  0.5966492 ]]\n",
      "\n",
      "# normal 2:\n",
      "[[ 1.0934397   1.2373759 ]\n",
      " [-0.02992922  1.0451084 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "\n",
    "x_shape = tf.shape(x)\n",
    "\n",
    "x_randn = tf.random_normal(shape=x_shape)\n",
    "\n",
    "x_data = np.empty((2, 3))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('# xのshape:')\n",
    "    print(sess.run(x_shape, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# normal 1:')\n",
    "    print(sess.run(x_randn, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# normal 2:')\n",
    "    print(sess.run(x_randn, feed_dict={x: x_data[:, :2]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4. 変形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# x:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "# tf.expand_dims:\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]]\n",
      "\n",
      "# tf.transpose:\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "# tf.reshape:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "\n",
      "# tf.tile:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "# tf.split:\n",
      "[array([[1., 1., 1.]], dtype=float32), array([[1., 1., 1.]], dtype=float32)]\n",
      "\n",
      "# tf.concat\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 全要素が1の行列\n",
    "x = tf.ones((2, 3))\n",
    "\n",
    "# 次元の追加: 指定したaxisに新たに次元を追加\n",
    "x_expand_dims = tf.expand_dims(x, axis=2) # x[:, :, None], x[:, :, tf.newaxis] でも同じ\n",
    "\n",
    "# 次元の入れ替え\n",
    "x_transpose = tf.transpose(x, perm=(1, 0))\n",
    "\n",
    "# 変形\n",
    "x_reshape = tf.reshape(x, shape=(6, 1))\n",
    "\n",
    "# 繰り返し\n",
    "x_tile = tf.tile(input=x, multiples=(2, 1))\n",
    "\n",
    "# 分割: axisに沿って変数をnum_or_size_splits個に分割\n",
    "x_split1, x_split2 = tf.split(value=x, num_or_size_splits=2, axis=0)\n",
    "\n",
    "# 連結\n",
    "x_concat = tf.concat([x_split1, x_split2], axis=0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('# x:')\n",
    "    print(sess.run(x))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.expand_dims:')\n",
    "    print(sess.run(x_expand_dims))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.transpose:')\n",
    "    print(sess.run(x_transpose))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.reshape:')\n",
    "    print(sess.run(x_reshape))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.tile:')\n",
    "    print(sess.run(x_tile))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.split:')\n",
    "    print(sess.run([x_split1, x_split2]))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.concat')\n",
    "    print(sess.run(x_concat))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5. 行列・テンソル積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np` の `dot`、`matmul` に対応するものは `tf.matmul` ですが、少し挙動が違うので注意する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 行列積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.matmul`もしくは`@`を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones((2, 3))\n",
    "b = tf.ones((3, 4))\n",
    "\n",
    "c = tf.matmul(a, b) # a @ b でも可\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベクトルに対しても `None` などで明示的に行列に変換する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones((2,2))\n",
    "b = tf.ones(2)\n",
    "\n",
    "# c = tf.matmul(a, b) # エラー\n",
    "c = tf.matmul(a, b[:, None])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6. テンソル積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np`と同様に`tf`にも`einsum`があります。3階以上のテンソルを含む計算はこれを用いるのがわかりやすくベターです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 6. 6. 6.]\n",
      "24.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones((2,3,4))\n",
    "b = tf.ones((2,3))\n",
    "\n",
    "c = tf.einsum('ijk,ij->k', a, b)\n",
    "c_sum = tf.einsum('ijk,ij->', a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(c.eval())\n",
    "    print(c_sum.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. 数学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. スカラー演算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APIはNumPyと非常に似ています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03856168 0.78010046]\n",
      "\n",
      "# exp:\n",
      "[1.0393149 2.1816916]\n",
      "\n",
      "# log:\n",
      "[-3.2554963  -0.24833257]\n",
      "\n",
      "# sqrt:\n",
      "[0.19637127 0.88323295]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(34)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "x_exp = tf.exp(x)\n",
    "x_log = tf.log(x)\n",
    "x_sqrt = tf.sqrt(x)\n",
    "\n",
    "x_data = np.random.random(2)\n",
    "print(x_data)\n",
    "print()\n",
    "with tf.Session() as sess:\n",
    "    print('# exp:')\n",
    "    print(sess.run(x_exp, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# log:')\n",
    "    print(sess.run(x_log, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# sqrt:')\n",
    "    print(sess.run(x_sqrt, feed_dict={x: x_data}))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークなどで使われる活性化関数は`tf.nn`以下にあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# x:\n",
      "[[0.09270376 0.63289269 0.01389085]\n",
      " [0.93615854 0.42657438 0.25308645]]\n",
      "\n",
      "# sigmoid:\n",
      "[[0.5231593  0.6531451  0.5034726 ]\n",
      " [0.71832305 0.6050554  0.562936  ]]\n",
      "\n",
      "# tanh:\n",
      "[[0.0924391  0.56004083 0.01388996]\n",
      " [0.7334523  0.40245453 0.24781777]]\n",
      "\n",
      "# relu:\n",
      "[[0.09270375 0.63289267 0.01389085]\n",
      " [0.93615854 0.42657438 0.25308645]]\n",
      "\n",
      "# elu:\n",
      "[[0.09270375 0.63289267 0.01389085]\n",
      " [0.93615854 0.42657438 0.25308645]]\n",
      "\n",
      "# softplus:\n",
      "[[0.74057287 1.0588486  0.70011663]\n",
      " [1.2669944  0.92900974 0.8276757 ]]\n",
      "\n",
      "# softmax:\n",
      "[[0.2746842  0.47144905 0.2538667 ]\n",
      " [0.47487703 0.28528017 0.23984282]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "x_sigmoid = tf.nn.sigmoid(x)\n",
    "\n",
    "x_tanh = tf.nn.tanh(x) # tf.tanhでも可\n",
    "\n",
    "x_relu = tf.nn.relu(x)\n",
    "\n",
    "x_elu = tf.nn.elu(x)\n",
    "\n",
    "x_softplus = tf.nn.softplus(x)\n",
    "\n",
    "# 正規化したい軸を指定する (ver. 1.4以前はdim、ver. 1.5以降ではaxis)。最後の軸に対して行いたいときは-1\n",
    "x_softmax = tf.nn.softmax(x, axis=-1)\n",
    "\n",
    "x_data = np.random.random((2, 3))\n",
    "print('# x:')\n",
    "print(x_data)\n",
    "print()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('# sigmoid:')\n",
    "    print(sess.run(x_sigmoid, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# tanh:')\n",
    "    print(sess.run(x_tanh, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# relu:')\n",
    "    print(sess.run(x_relu, feed_dict={x: x_data}))\n",
    "    print()\n",
    "\n",
    "    print('# elu:')\n",
    "    print(sess.run(x_elu, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# softplus:')\n",
    "    print(sess.run(x_softplus, feed_dict={x: x_data}))\n",
    "    print()\n",
    "\n",
    "    print('# softmax:')\n",
    "    print(sess.run(x_softmax, feed_dict={x: x_data}))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. 集約演算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引数`axis`で指定した軸に沿って演算を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# x:\n",
      "[[ 0.9190819   0.23504311  0.14727762]\n",
      " [-1.8283275  -1.0419803   0.28557974]]\n",
      "\n",
      "# 合計:\n",
      "[-0.9092456  -0.80693716  0.43285736]\n",
      "\n",
      "# 平均:\n",
      "[-0.4546228  -0.40346858  0.21642868]\n",
      "\n",
      "# 分散:\n",
      "[1.8870646  0.40769714 0.00478187]\n",
      "\n",
      "# 最大値:\n",
      "[0.9190819  0.23504311 0.28557974]\n",
      "\n",
      "# 最小値:\n",
      "[-1.8283275  -1.0419803   0.14727762]\n",
      "\n",
      "# 最大値のindex:\n",
      "[0 0 1]\n",
      "\n",
      "# 最小値のindex:\n",
      "[1 1 0]\n",
      "\n",
      "# ノルム:\n",
      "[2.0463367 1.0681611 0.3213199]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_normal((2, 3))\n",
    "\n",
    "x_sum = tf.reduce_sum(x, axis=0)\n",
    "\n",
    "# 平均, 分散\n",
    "x_mean, x_var = tf.nn.moments(x, axes=0) # 平均はtf.reduce_meanでも可\n",
    "\n",
    "# 最大値\n",
    "x_max = tf.reduce_max(input_tensor=x, axis=0)\n",
    "\n",
    "# 最小値\n",
    "x_min = tf.reduce_min(input_tensor=x, axis=0)\n",
    "\n",
    "# 最大値のindex\n",
    "x_argmax = tf.argmax(input=x, axis=0)\n",
    "\n",
    "# 最小値のindex\n",
    "x_argmin = tf.argmin(input=x, axis=0)\n",
    "\n",
    "# ノルム\n",
    "x_norm = tf.norm(tensor=x, ord=2, axis=0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x_, x_sum_, x_mean_, x_var_, x_max_, x_min_, x_argmax_, x_argmin_, x_norm_ = sess.run(\n",
    "        [x, x_sum, x_mean, x_var, x_max, x_min, x_argmax, x_argmin, x_norm])\n",
    "    \n",
    "    print('# x:')\n",
    "    print(x_)\n",
    "    print()\n",
    "    \n",
    "    print('# 合計:')\n",
    "    print(x_sum_)\n",
    "    print()\n",
    "    \n",
    "    print('# 平均:')\n",
    "    print(x_mean_)\n",
    "    print()\n",
    "    \n",
    "    print('# 分散:')\n",
    "    print(x_var_)\n",
    "    print()\n",
    "\n",
    "    print('# 最大値:')\n",
    "    print(x_max_)\n",
    "    print()\n",
    "    \n",
    "    print('# 最小値:')\n",
    "    print(x_min_)\n",
    "    print()\n",
    "    \n",
    "    print('# 最大値のindex:')\n",
    "    print(x_argmax_)\n",
    "    print()\n",
    "    \n",
    "    print('# 最小値のindex:')\n",
    "    print(x_argmin_)\n",
    "    print()\n",
    "    \n",
    "    print('# ノルム:')\n",
    "    print(x_norm_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. 制御構文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1. 条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常のPythonの`if`に対応するものは`tf.cond`です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = tf.placeholder(tf.float32, name='y')\n",
    "\n",
    "absl = tf.cond(\n",
    "    pred=x > y,\n",
    "    true_fn=lambda: x - y,\n",
    "    false_fn=lambda: y - x\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(absl, feed_dict={x: 100, y:  50}))\n",
    "    print(sess.run(absl, feed_dict={x:  50, y: 100}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数の各要素に対して条件付ける場合は`tf.where`を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# x:\n",
      "[[-0.3263399  -0.7688404   1.7880154 ]\n",
      " [-1.8622563  -0.58020264  0.6365889 ]]\n",
      "\n",
      "# tf.where(x):\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_normal((2, 3))\n",
    "\n",
    "x_where = tf.where(\n",
    "    condition=x > 0,\n",
    "    x=tf.ones_like(x),\n",
    "    y=tf.zeros_like(x)\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x_, x_where_ = sess.run([x, x_where])\n",
    "    \n",
    "    print('# x:')\n",
    "    print(x_)\n",
    "    print()\n",
    "    \n",
    "    print('# tf.where(x):')\n",
    "    print(x_where_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数を一定の値でclipしたい場合は`tf.clip_by_value`を使います。例えばlogの中身が0になるのを防ぐときなどに使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# x:\n",
      "[[ 1.5167398   2.0579255   0.44247675]\n",
      " [ 1.801229    0.10361186 -0.41155642]]\n",
      "\n",
      "# tf_log(x):\n",
      "[[  0.41656318   0.7216984   -0.81536734]\n",
      " [  0.5884692   -2.2671034  -16.118095  ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_normal((2, 3))\n",
    "\n",
    "x_log = tf.log(tf.clip_by_value(t=x, clip_value_min=1e-7, clip_value_max=x))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x_, x_log_ = sess.run([x, x_log])\n",
    "    \n",
    "    print('# x:')\n",
    "    print(x_)\n",
    "    print()\n",
    "    \n",
    "    print('# tf_log(x):')\n",
    "    print(x_log_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.log`などよく使うものは関数化しておくと便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2. 比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比較演算子は\n",
    "- `tf.equal`\n",
    "- `tf.not_equal`\n",
    "- `tf.greater`\n",
    "- `tf.less`\n",
    "\n",
    "などを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = tf.placeholder(tf.float32, name='y')\n",
    "\n",
    "absl = tf.cond(\n",
    "    pred=tf.greater(x, y),\n",
    "    true_fn=lambda: x - y,\n",
    "    false_fn=lambda: y - x\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(absl, feed_dict={x: 100, y:  50}))\n",
    "    print(sess.run(absl, feed_dict={x:  50, y: 100}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他の言語の`for`、`while`に対応するものはそれぞれ`tf.scan`、`tf.while_loop`です。これはRNNの回で詳細に扱います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. 勾配 (微分) の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.gradients`をつかうことで微分を計算することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0]\n",
      "[4.0]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = x**2\n",
    "\n",
    "grads = tf.gradients(y, x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(grads, feed_dict={x: 1.}))\n",
    "    print(sess.run(grads, feed_dict={x: 2.}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二引数(`xs`)に複数の変数を指定すると、それぞれに対する偏微分をリストで返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 64.0]\n",
      "[18.0, 512.0]\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.placeholder(tf.float32, name='x1')\n",
    "x2 = tf.placeholder(tf.float32, name='x2')\n",
    "y = 3*x1**2 + 2*x2**4\n",
    "\n",
    "grads = tf.gradients(y, [x1, x2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(grads, feed_dict={x1: 1, x2: 2}))\n",
    "    print(sess.run(grads, feed_dict={x1: 3, x2: 4}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. 変数の値の更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Variable`の値を更新するには `assign`、`assign_add`、`assign_sub`を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.0, name='w')\n",
    "\n",
    "increment_a = a.assign_add(1.)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        print(sess.run(increment_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数の更新をまとめる場合は `tf.group` を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1.0,  b: 9.0\n",
      "a: 2.0,  b: 8.0\n",
      "a: 3.0,  b: 7.0\n",
      "a: 4.0,  b: 6.0\n",
      "a: 5.0,  b: 5.0\n",
      "a: 6.0,  b: 4.0\n",
      "a: 7.0,  b: 3.0\n",
      "a: 8.0,  b: 2.0\n",
      "a: 9.0,  b: 1.0\n",
      "a: 10.0,  b: 0.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.0, name='a')\n",
    "b = tf.Variable(10.0, name='b')\n",
    "\n",
    "increment_a = a.assign_add(1.)\n",
    "decrement_b = b.assign_sub(1.)\n",
    "\n",
    "updates = [\n",
    "    increment_a,\n",
    "    decrement_b\n",
    "]\n",
    "\n",
    "update = tf.group(*updates)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(update)\n",
    "        print('a:', a.eval(), end=',  ')\n",
    "        print('b:', b.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更新に順序をつけたい場合は`tf.control_dependencies`を利用します。\n",
    "\n",
    "Optimizerを実装するときなどに使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "25\n",
      "676\n",
      "458329\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.Variable(0, name='a')\n",
    "\n",
    "increment_a = a.assign_add(1)\n",
    "with tf.control_dependencies([increment_a]):\n",
    "    square_a = a.assign(a * a)\n",
    "\n",
    "update = tf.group(*[increment_a, square_a])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(5):\n",
    "        sess.run(update)\n",
    "        print(sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorFlow応用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. TensorBoardによるグラフの表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowで計算グラフの構築方法を扱ってきましたが、ここでは構築した計算グラフの可視化をし、視覚的に捉えてみましょう。\n",
    "\n",
    "計算グラフを表示するには、`tensorboard.py` を読み込む必要があります。\n",
    "\n",
    "tensorboard.pyをimportしたら、show_graph関数にグラフを渡すことで可視化できます。\n",
    "\n",
    "可視化結果はインタラクティブな表示になるので、拡大や移動、詳細表示等を試してみましょう。\n",
    "\n",
    "出典: jupyter上に、tensorBoardのグラフを表示させる\n",
    ": https://qiita.com/kegamin/items/887c7dfe8bbb76197741 (2018年9月20日参照)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.18996530629366992&quot;).pbtxt = 'node {\\n  name: &quot;a/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;a&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;a/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;a&quot;\\n  input: &quot;a/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@a&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;a/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;a&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@a&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AssignAdd/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;AssignAdd&quot;\\n  op: &quot;AssignAdd&quot;\\n  input: &quot;a&quot;\\n  input: &quot;AssignAdd/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@a&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;a/read&quot;\\n  input: &quot;a/read&quot;\\n  input: &quot;^AssignAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;a&quot;\\n  input: &quot;mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@a&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Assign&quot;\\n  input: &quot;^AssignAdd&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^a/Assign&quot;\\n}\\nnode {\\n  name: &quot;a_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;a_1&quot;\\n  input: &quot;b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.18996530629366992&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorboard as tb\n",
    "\n",
    "a = tf.placeholder(tf.float32, name='a')\n",
    "b = tf.placeholder(tf.float32, name='b')\n",
    "\n",
    "c = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([c], feed_dict={a:2, b:3}))\n",
    "\n",
    "tb.show_graph(sess.graph)    # 単純な足し算のグラフの表示 (がしたいが...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. グラフの管理と整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. デフォルトグラフによる管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`では特に何も指定しなければ、デフォルトグラフと呼ばれるグラフ上に計算グラフが構築されていきます。\n",
    "一度計算グラフ上に配置されたグラフは、そのグラフを使うか使わないかにかかわらず、全てリセットされることなく蓄積されていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a/initial_value' type=Const>,\n",
       " <tf.Operation 'a' type=VariableV2>,\n",
       " <tf.Operation 'a/Assign' type=Assign>,\n",
       " <tf.Operation 'a/read' type=Identity>,\n",
       " <tf.Operation 'AssignAdd/value' type=Const>,\n",
       " <tf.Operation 'AssignAdd' type=AssignAdd>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'Assign' type=Assign>,\n",
       " <tf.Operation 'group_deps' type=NoOp>,\n",
       " <tf.Operation 'init' type=NoOp>,\n",
       " <tf.Operation 'a_1' type=Placeholder>,\n",
       " <tf.Operation 'b' type=Placeholder>,\n",
       " <tf.Operation 'add' type=Add>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 今までの実行によりデフォルトグラフ上に溜まったオペレーション\n",
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'a:0' shape=() dtype=int32_ref>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 今までの実行によりデフォルトグラフ上に溜まったVariables\n",
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そのため、このままでは使わないゴミリソースが蓄積され続けてしまいます。\n",
    "\n",
    "`tf.reset_default_graph`を毎回新しくグラフを構築する際に呼び出すことにより、これを避けることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.4148246329367714&quot;).pbtxt = 'node {\\n  name: &quot;x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;t&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;W&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;zeros/shape_as_tensor&quot;\\n  input: &quot;zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;b&quot;\\n  input: &quot;zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x&quot;\\n  input: &quot;W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul&quot;\\n  input: &quot;b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;y&quot;\\n  input: &quot;t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;pow/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;pow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;range/start&quot;\\n  input: &quot;Rank&quot;\\n  input: &quot;range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;pow&quot;\\n  input: &quot;range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.4148246329367714&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフのリセット\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# プレースホルダーと変数の宣言\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "W = tf.Variable(tf.random_uniform((5, 3), -1.0, 1.0), name='W')\n",
    "b = tf.Variable(tf.zeros((3)), name='b')\n",
    "\n",
    "# グラフの構築\n",
    "y = tf.add(tf.matmul(x, W), b, name='y')\n",
    "\n",
    "# 誤差関数の定義\n",
    "cost = tf.reduce_mean((y - t)**2, name='cost')\n",
    "\n",
    "tb.show_graph(tf.Session().graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. namespaceによる管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.reset_default_graph`を呼び出すことにより、毎回クリーンな状態でグラフを構築していくことができます。\n",
    "ただグラフが大規模になってくると、以前変数が多くなりグラフtensorboard上などでノードが見づらくなってしまいます。\n",
    "\n",
    "tf.name_scope関数を使ってノードをグループに分けることにより、この問題を解消することができます。\n",
    "\n",
    "まとめられたノードは、カーソルをかざすと出てくる右上のプラスマークをクリックすることで展開することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.013420609739402511&quot;).pbtxt = 'node {\\n  name: &quot;x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;t&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;variables/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;variables/random_uniform/max&quot;\\n  input: &quot;variables/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;variables/random_uniform/RandomUniform&quot;\\n  input: &quot;variables/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;variables/random_uniform/mul&quot;\\n  input: &quot;variables/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;variables/W&quot;\\n  input: &quot;variables/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;variables/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;variables/zeros/shape_as_tensor&quot;\\n  input: &quot;variables/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;variables/b&quot;\\n  input: &quot;variables/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;variables/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;model/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x&quot;\\n  input: &quot;variables/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;model/y&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;model/MatMul&quot;\\n  input: &quot;variables/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;model/y&quot;\\n  input: &quot;t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;training/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;training/Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;training/range/start&quot;\\n  input: &quot;training/Rank&quot;\\n  input: &quot;training/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/cost&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;training/Square&quot;\\n  input: &quot;training/range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.013420609739402511&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "\n",
    "with tf.name_scope('variables'):\n",
    "    W = tf.Variable(tf.random_uniform((5, 3), -1.0, 1.0), name='W')\n",
    "    b = tf.Variable(tf.zeros((3)), name='b')\n",
    "\n",
    "with tf.name_scope('model'):\n",
    "    y = tf.add(tf.matmul(x, W), b, name='y')\n",
    "\n",
    "with tf.name_scope('training'):\n",
    "    cost = tf.reduce_mean(tf.square(y - t), name='cost')\n",
    "\n",
    "tb.show_graph(tf.Session().graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3. グラフの切り分けによる管理\n",
    "\n",
    "デフォルトグラフではなく、明示的にグラフオブジェクトを作成し、その上にグラフを構築していくことでグラフ環境を他と分けることも可能です。\n",
    "\n",
    "これは複数のグラフを構築していきたいときなどに便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "g0 = tf.get_default_graph() # デフォルトグラフオブジェクトを取得することも可能\n",
    "\n",
    "g1 = tf.Graph() # グラフオブジェクトの作成1\n",
    "\n",
    "a = tf.constant(2, name='a0') # これはdefault graphへの配置になるので注意\n",
    "b = a**a\n",
    "\n",
    "with g1.as_default(): # デフォルトに設定した上で, グラフを構築・操作\n",
    "    a = tf.constant(2, name='a')\n",
    "    b = a**a\n",
    "\n",
    "g2 = tf.Graph() # グラフオブジェクトの作成2\n",
    "\n",
    "with g2.as_default(): # デフォルトに設定し, グラフを構築\n",
    "    a = tf.constant(4, name='a')\n",
    "    x = tf.constant(3, name='x')\n",
    "    y = a**x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.6484727848231905&quot;).pbtxt = 'node {\\n  name: &quot;a0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;a0&quot;\\n  input: &quot;a0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.6484727848231905&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tb.show_graph(g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.8693687459490342&quot;).pbtxt = 'node {\\n  name: &quot;a&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;a&quot;\\n  input: &quot;a&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.8693687459490342&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(graph=g1) as sess:\n",
    "    print(sess.run(b))\n",
    "tb.show_graph(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.6090357034477198&quot;).pbtxt = 'node {\\n  name: &quot;a&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;a&quot;\\n  input: &quot;x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.6090357034477198&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(graph=g2) as sess:\n",
    "    print(sess.run(y))\n",
    "tb.show_graph(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. モデルの保存・読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.train.Saver`を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ (OR)\n",
    "x_data = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
    "t_data = np.array([[1], [1], [0], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 100, Train Cost, 0.158\n",
      "EPOCH: 200, Train Cost, 0.090\n",
      "EPOCH: 300, Train Cost, 0.062\n",
      "EPOCH: 400, Train Cost, 0.047\n",
      "EPOCH: 500, Train Cost, 0.038\n",
      "EPOCH: 600, Train Cost, 0.032\n",
      "EPOCH: 700, Train Cost, 0.027\n",
      "EPOCH: 800, Train Cost, 0.024\n",
      "EPOCH: 900, Train Cost, 0.021\n",
      "EPOCH: 1000, Train Cost, 0.019\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.98354787],\n",
       "       [0.9835476 ],\n",
       "       [0.04127072],\n",
       "       [0.99998796]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='x')\n",
    "t = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='t')\n",
    "\n",
    "W = tf.Variable(tf.random_uniform(shape=(2, 1), minval=-0.08, maxval=0.08, dtype=tf.float32), name='W')\n",
    "b = tf.Variable(tf.zeros(shape=(1), dtype=tf.float32), name='b')\n",
    "\n",
    "y = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf.log(y) + (1 - t) * tf.log(1 - y), axis=1))\n",
    "\n",
    "gW, gb = tf.gradients(cost, [W, b]) # 勾配の計算\n",
    "updates = [\n",
    "    W.assign_sub(0.5 * gW), # 勾配降下法\n",
    "    b.assign_sub(0.5 * gb)\n",
    "]\n",
    "train = tf.group(*updates)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 重み (Variable) の初期化\n",
    "for epoch in range(1000):\n",
    "    cost_, _ = sess.run([cost, train], feed_dict={x: x_data, t: t_data})\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('EPOCH: {}, Train Cost, {:.3f}'.format(epoch + 1, cost_))\n",
    "\n",
    "print()\n",
    "y_pred = sess.run(y, feed_dict={x: x_data})\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/model.ckpt'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, '/tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='x')\n",
    "t = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='t')\n",
    "\n",
    "W = tf.Variable(tf.random_uniform(shape=(2, 1), minval=-0.08, maxval=0.08, dtype=tf.float32), name='W')\n",
    "b = tf.Variable(tf.zeros(shape=(1), dtype=tf.float32), name='b')\n",
    "\n",
    "y = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, '/tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98354787],\n",
       "       [0.9835476 ],\n",
       "       [0.04127072],\n",
       "       [0.99998796]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sess.run(y, feed_dict={x: x_data})\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. メモリの管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowは、デフォルトでは最初のSessionを開始した時点でシステム上のすべてのGPUのすべてのメモリを専有してしまいます。これは共用のサーバーなどでは特に避けなければいけません。(iLect上では特に気にしなくて大丈夫です。）\n",
    "\n",
    "ここではいくつかの方法で使用するメモリを制御するいくつかの方法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1. 使用するGPU(数)を制限する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`から見えるGPUを制限します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定したgpu上にグラフを展開していきます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    x = tf.zeros(4)\n",
    "    # グラフの構築\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 GPU上のメモリ使用量を制限する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`ではGPUメモリ上に最初にオブジェクトが展開される際、そのオブジェクトのサイズにかかわらずGPU上のすべてのメモリを専有してしまいます。\n",
    "\n",
    "これをオブジェクトのサイズに応じて段階的にメモリが使用されるように変更します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "x = tf.random_normal((100, 100))\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    pass\n",
    "\n",
    "# ! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`が一定割合のメモリのみ使用できるように設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5 # 50%のメモリのみ使用\n",
    "\n",
    "x = tf.random_normal((100, 100))\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    pass\n",
    "\n",
    "# ! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詳細は https://www.tensorflow.org/guide/using_gpu を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. `tf.data` APIの利用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(以下の説明は`tf.data`の公式ドキュメント https://www.tensorflow.org/guide/datasets を元にしています)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いままでは`feed_dict`に毎回NumPyオブジェクト等を流し込むことにより学習ループを回していました。\n",
    "\n",
    "もう一つの方法として事前にデータを`tf`のオブジェクト`tf.data.Dataset`に変換し、毎回のNumPyオブジェクトからの変換を省くやり方があります。\n",
    "\n",
    "入力データが大規模になったり複数のGPUを使う際にはこれにより学習の高速化が期待できます。(参考: Tensorflow Performance Guide: https://www.tensorflow.org/performance/performance_guide)\n",
    "\n",
    "この場合、グラフの構築の際に\n",
    "\n",
    "1. NumPyオブジェクトから`Dataset`オブジェクトへの変換\n",
    "2. Iteratorの設定\n",
    "\n",
    "を行う必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1. `tf.data.Dataset`\n",
    "\n",
    "まず通常のメモリ上のデータ (ndarray等) から`tf.data.Dataset`に変換します。これには`tf.data.Dataset.from_tensor_slices`などを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ (OR)\n",
    "x_data = np.array([[0, 1], [1, 0], [0, 0], [1, 1]]).astype(np.float32)\n",
    "t_data = np.array([[1], [1], [0], [1]]).astype(np.float32)\n",
    "\n",
    "x_train, t_train = x_data, t_data\n",
    "x_valid, t_valid = x_data, t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# ndarrayからDatasetへ変換\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "\n",
    "# 複数のオブジェクトをまとめて変換する場合はタプルで渡す\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, t_train))\n",
    "\n",
    "# Dataset同士をまとめる場合はDataset.zipを利用\n",
    "dataset_x = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "dataset_t = tf.data.Dataset.from_tensor_slices(t_train)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_x, dataset_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また`tf.placeholder`を利用して空の`Dataset`を作成することも可能です。ただしこの場合はデータを別の方法で流し込む必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "# 型情報のみが保存される\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、`shuffle`、`batch`、`repeat`、`map`等を利用して前処理部分を書くことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# ndarrayからDatasetへ変換\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "\n",
    "# 適当な前処理\n",
    "dataset = dataset.map(lambda x: x * tf.random_normal([], dtype=tf.float32))\n",
    "\n",
    "# Dataset内のシャッフル (引数でシャッフル時のバッファ数を指定)\n",
    "dataset = dataset.shuffle(len(x_data))\n",
    "\n",
    "# データセットを繰り返す回数 (エポック数) を指定\n",
    "dataset = dataset.repeat(3)\n",
    "\n",
    "# バッチサイズを指定. 次元が最初に1つ追加される\n",
    "print(dataset.output_shapes)\n",
    "dataset = dataset.batch(4)\n",
    "print(dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2. `tf.data.Iterator`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にIteratorにより、`Dataset`内の要素をどのように走査するかを決めていきます。\n",
    "\n",
    "現在4つのIterator (One-shot, Initializable, Reinitializable, Feedable) が用意されています。後ろに行くほど柔軟性が高いものになっています。またどのIteratorにおいても走査終了時にはエラー ('tf.errors.OutOfRangeError') が投げられます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-shot iterator\n",
    "Datasetを一回だけ走査するiteratorです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of dataset\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_data).shuffle(len(x_data))\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "x = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(x)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of dataset')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initializable iterator\n",
    "one-shot iteratorと違い再利用可能なiteratorです。`iterator.initializer`によって初期化してから使用します。\n",
    "\n",
    "主に`tf.placeholder`などから作成された空の`Dataset`に対して適用します。\n",
    "\n",
    "訓練データと検証データを`tf.placeholder`で入れ替えたい場合などに便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of train dataset\n",
      "End of valid dataset\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data = tf.placeholder(tf.float32, shape=(4, 2))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "x = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Train\n",
    "    sess.run(iterator.initializer, feed_dict={data: x_train})\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(x)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of train dataset')\n",
    "            break\n",
    "    \n",
    "    # Valid\n",
    "    sess.run(iterator.initializer, feed_dict={data: x_valid})\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(x)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of valid dataset')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reinitializable iterator\n",
    "型情報のみから作成されるIteratorです。\n",
    "\n",
    "異なる`Dataset`に渡って使用することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of train dataset\n",
      "End of valid dataset\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "dataset_train = dataset_train.map(lambda x: x + tf.random_normal([]))\n",
    "\n",
    "dataset_valid = tf.data.Dataset.from_tensor_slices(x_valid)\n",
    "\n",
    "# Iteratorの型を指定\n",
    "iterator = tf.data.Iterator.from_structure(\n",
    "    output_types=dataset_train.output_types,\n",
    "    output_shapes=dataset_train.output_shapes\n",
    ")\n",
    "\n",
    "x = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Train\n",
    "    sess.run(iterator.make_initializer(dataset_train)) # 訓練データでiteratorを初期化\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(x)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of train dataset')\n",
    "            break\n",
    "    \n",
    "    # Valid\n",
    "    sess.run(iterator.make_initializer(dataset_valid)) # 検証データでiteratorを初期化\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(x)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of valid dataset')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feedable iterator\n",
    "どのIteratorを操作するかを柔軟に決めることのできるIteratorです。複数のIteratorの中からどれをiterateするかをfeed_dictにより指定して実行します。\n",
    "\n",
    "Iteratorを初期化することなく複数のIterator間を行き来できるので、たとえば訓練データの一定iterationごとに検証データを回したいなどの場面で有用です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100\n",
      "End of validation dataset\n",
      "\n",
      "Iteration: 200\n",
      "End of validation dataset\n",
      "\n",
      "Iteration: 300\n",
      "End of validation dataset\n",
      "\n",
      "Iteration: 400\n",
      "End of validation dataset\n",
      "\n",
      "Iteration: 500\n",
      "End of validation dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, t_train))\n",
    "dataset_train = dataset_train.repeat()\n",
    "\n",
    "dataset_valid = tf.data.Dataset.from_tensor_slices((x_valid, t_valid))\n",
    "\n",
    "handle = tf.placeholder(tf.string)\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    string_handle=handle,\n",
    "    output_types=dataset_train.output_types,\n",
    "    output_shapes=dataset_train.output_shapes\n",
    ")\n",
    "\n",
    "iterator_train = dataset_train.make_one_shot_iterator()\n",
    "iterator_valid = dataset_valid.make_initializable_iterator()\n",
    "\n",
    "x, t = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    handle_train = sess.run(iterator_train.string_handle())\n",
    "    handle_valid = sess.run(iterator_valid.string_handle())\n",
    "        \n",
    "    # Train\n",
    "    for i in range(500):\n",
    "        sess.run(x, feed_dict={handle: handle_train})\n",
    "\n",
    "        # 100回繰り返すごとにvalidation\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Iteration: {}'.format(i + 1))\n",
    "            # Valid\n",
    "            sess.run(iterator_valid.initializer)\n",
    "            while True:\n",
    "                try:\n",
    "                    sess.run(x, feed_dict={handle: handle_valid})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    print('End of validation dataset')\n",
    "                    break\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TensorFlowによるニューラルネットワークの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.gradients`を使うことで様々なOptimizerを実装することができます。\n",
    "\n",
    "(tfにはbuilt-inで様々なOptimizerが実装されていますが、今回のchap05ではそのような高レベルAPIは使用せず、代わりに各自で実装していただきます。宿題においても同様です。）\n",
    "\n",
    "いくつかのOptimizerを例として以下に示します。また、個々の学習パラメータ (${\\bf W}$や${\\bf b}$の各要素)を以下では一般化して$\\theta\\in\\mathbb{R}$で表しています。\n",
    "また、ステップ$t$における誤差関数$E$に対する学習パラメータ$\\theta$の微分を$g_{t}$で表します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD\n",
    "\n",
    "\\begin{align*}\n",
    "    \\theta_{t+1} = \\theta_{t} - \\eta \\cdot g_{t}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(cost, params, eta=0.01):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        updates.append(param.assign_sub(eta * grad))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum\n",
    "\n",
    "\\begin{align*}\n",
    "    v_{t} = \\gamma v_{t-1} + \\eta \\cdot g_{t} \\\\\n",
    "    \\theta_{t+1} = \\theta_{t} - v_{t}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(cost, params, eta=0.01, gamma=0.9):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        v = tf.Variable(tf.zeros_like(param, dtype=tf.float32), name='v')\n",
    "        updates.append(v.assign(gamma * v + eta * grad))\n",
    "        with tf.control_dependencies(updates):\n",
    "            updates.append(param.assign_sub(v))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adagrad\n",
    "\n",
    "\\begin{align*}\n",
    "    G_{t} = G_{t-1} + g^{2}_t \\\\\n",
    "    \\theta_{t+1} = \\theta_{t} - \\frac{\\eta}{\\sqrt{G_{t} + \\epsilon}} \\cdot g_{t}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adagrad(cost, params, eta=0.01, eps=1e-7):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        G = tf.Variable(tf.zeros_like(param, dtype=tf.float32), name='G')\n",
    "        updates.append(G.assign_add(grad**2))\n",
    "        with tf.control_dependencies(updates):\n",
    "            updates.append(param.assign_sub(eta / tf.sqrt(G + eps) * grad))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp\n",
    "\n",
    "\\begin{align*}\n",
    "    \\tilde{G}_{t} = \\rho \\cdot \\tilde{G}_{t-1} + (1 - \\rho) \\cdot g^{2}_{t} \\\\\n",
    "    \\theta_{t+1} = \\theta_{t} - \\frac{\\eta}{\\sqrt{\\tilde{G}_{t} + \\epsilon}} \\cdot g_{t}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsprop(cost, params, eta=0.001, rho=0.9, eps=1e-7):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        G = tf.Variable(tf.zeros_like(param, dtype=tf.float32), name='G')\n",
    "        updates.append(G.assign(rho * G + (1 - rho) * grad**2))\n",
    "        with tf.control_dependencies(updates):\n",
    "            updates.append(param.assign_sub(eta / tf.sqrt(G + eps) * grad))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adadelta、Adam等も同じ要領で実装できるので、余裕のある人は実装してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropoutを適用するには`tf.nn.dropout`を使います。\n",
    "\n",
    "引数の`keep_prob`でユニットをキープする確率を設定します。また、関数の出力は$\\frac{1}{\\text{keep_prob}}$倍されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 0. 2. 0. 2. 0. 0. 2. 0.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(34)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "x_dropped = tf.nn.dropout(x, keep_prob=0.5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x_dropped, feed_dict={x: np.ones(10)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. 正則化 (重み減衰)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1正則化\n",
    "\\begin{align*}\n",
    "    \\tilde{E} = E + \\lambda \\sum_{\\theta} |\\theta|\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l1_reg(params):\n",
    "    l1_reg = 0\n",
    "    for param in params:\n",
    "        l1_reg += tf.reduce_sum(tf.abs(param))\n",
    "    return l1_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2正則化\n",
    "\\begin{align*}\n",
    "    \\tilde{E} = E + \\lambda \\sum_{\\theta} \\theta^2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l2_reg(params):\n",
    "    l2_reg = 0\n",
    "    for param in params:\n",
    "        l2_reg += tf.reduce_sum(tf.square(param)) # 2 * tf.nn.l2_lossを使っても良い\n",
    "    return l2_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. MLPの実装 (`tf.data.Dataset`を使用しない版)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowを使ってMLPを実装してみましょう。\n",
    "\n",
    "データセットにはMNISTを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, t_train), (x_valid, t_valid) = mnist.load_data()\n",
    "\n",
    "x_train = (x_train.reshape(-1, 784) / 255).astype(np.float32)\n",
    "x_valid = (x_valid.reshape(-1, 784) / 255).astype(np.float32)\n",
    "\n",
    "t_train = np.eye(10)[t_train].astype(np.float32)\n",
    "t_valid = np.eye(10)[t_valid].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層とDropout層からなるMLPを実装します。\n",
    "\n",
    "順伝播の式を示します。\n",
    "$$\n",
    "\\begin{align*}\n",
    "    {\\bf u}^{(1)} &= {\\bf W}^{(1)\\mathrm{T}} {\\bf x} + {\\bf b}^{(1)} \\\\\n",
    "    {\\bf h}^{(1)} &= \\mathrm{ReLU}({\\bf u}^{(1)}) \\\\\n",
    "    {\\bf \\tilde{h}}^{(1)} &= \\mathrm{Dropout}({\\bf h}^{(1)}) \\\\\n",
    "    {\\bf u}^{(2)} &= {\\bf W}^{(2)\\mathrm{T}} {\\bf \\tilde{h}}^{(1)} + {\\bf b}^{(2)} \\\\\n",
    "    {\\bf h}^{(2)} &= \\mathrm{ReLU}({\\bf u}^{(2)}) \\\\\n",
    "    {\\bf \\tilde{h}}^{(2)} &= \\mathrm{Dropout}({\\bf h}^{(2)}) \\\\\n",
    "    {\\bf u}^{(3)} &= {\\bf W}^{(3)\\mathrm{T}} {\\bf \\tilde{h}}^{(2)} + {\\bf b}^{(3)} \\\\\n",
    "    {\\bf y} &= \\mathrm{softmax} ({\\bf u}^{(3)})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層とDropout層を定義します。\n",
    "\n",
    "Dropout層では、訓練時と検証時のDropoutを適用の有無を`tf.cond`により制御します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        self.W = tf.Variable(tf.random_uniform(shape=(in_dim, out_dim), minval=-0.08, maxval=0.08), name='W')\n",
    "        self.b = tf.Variable(tf.zeros(out_dim), name='b')\n",
    "        self.function = function\n",
    "        \n",
    "        self.params = [self.W, self.b]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.function(tf.matmul(x, self.W) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_keep_prob=1.0):\n",
    "        self.dropout_keep_prob = dropout_keep_prob\n",
    "        self.params = []\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # 訓練時のみdropoutを適用\n",
    "        return tf.cond(\n",
    "            pred=is_training,\n",
    "            true_fn=lambda: tf.nn.dropout(x, keep_prob=self.dropout_keep_prob),\n",
    "            false_fn=lambda: x\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差関数は通常の他クラス交差エントロピーにL2正則化の項を追加したものを使用します。\n",
    "$$\n",
    "    E = -\\frac{1}{N}\\sum^N_{i=1} \\sum^K_{k=1} {\\bf t}_{i, k} \\log {\\bf y}_{i, k} + \\lambda\\sum_{\\theta}\\theta^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.log(0)によるnanを防ぐ\n",
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01 # 学習率\n",
    "dropout_keep_prob = 0.5 # Dropout率\n",
    "lmd = 0.001 # L2正則化項の係数\n",
    "batch_size = 32 # バッチサイズ\n",
    "n_epochs = 10 # epoch数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 784)) # 入力データ\n",
    "t = tf.placeholder(tf.float32, (None, 10)) # 教師データ\n",
    "is_training = tf.placeholder(tf.bool) # 訓練時orテスト時\n",
    "\n",
    "layers = [\n",
    "    Dense(784, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 10, tf.nn.softmax)\n",
    "]\n",
    "\n",
    "def get_params(layers):\n",
    "    params_all = []\n",
    "    for layer in layers:\n",
    "        params = layer.params\n",
    "        params_all.extend(params)\n",
    "    return params_all\n",
    "\n",
    "def f_props(layers, h):\n",
    "    for layer in layers:\n",
    "        h = layer(h)\n",
    "    return h\n",
    "\n",
    "y = f_props(layers, x)\n",
    "params_all = get_params(layers)\n",
    "l2_reg = compute_l2_reg(params_all)\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1)) + lmd * l2_reg\n",
    "\n",
    "updates = sgd(cost, params_all, eta)\n",
    "train = tf.group(*updates)\n",
    "\n",
    "n_batches = math.ceil(len(x_train) / batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Valid Cost: 0.875, Valid Accuracy: 0.881\n",
      "EPOCH: 2, Valid Cost: 0.730, Valid Accuracy: 0.910\n",
      "EPOCH: 3, Valid Cost: 0.660, Valid Accuracy: 0.923\n",
      "EPOCH: 4, Valid Cost: 0.608, Valid Accuracy: 0.933\n",
      "EPOCH: 5, Valid Cost: 0.570, Valid Accuracy: 0.939\n",
      "EPOCH: 6, Valid Cost: 0.537, Valid Accuracy: 0.944\n",
      "EPOCH: 7, Valid Cost: 0.506, Valid Accuracy: 0.946\n",
      "EPOCH: 8, Valid Cost: 0.483, Valid Accuracy: 0.950\n",
      "EPOCH: 9, Valid Cost: 0.461, Valid Accuracy: 0.952\n",
      "EPOCH: 10, Valid Cost: 0.442, Valid Accuracy: 0.955\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        x_train, t_train = shuffle(x_train, t_train)\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end], is_training: True})\n",
    "        y_pred, cost_valid_ = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid, is_training: False})\n",
    "        print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "            epoch + 1,\n",
    "            cost_valid_,\n",
    "            accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. `tf.data.Dataset`を用いた実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考として`tf.data.Dataset`を使用した実装を以下に示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2000, Valid Cost: 0.870, Valid Accuracy: 0.882\n",
      "Iteration: 4000, Valid Cost: 0.724, Valid Accuracy: 0.908\n",
      "Iteration: 6000, Valid Cost: 0.653, Valid Accuracy: 0.923\n",
      "Iteration: 8000, Valid Cost: 0.602, Valid Accuracy: 0.932\n",
      "Iteration: 10000, Valid Cost: 0.562, Valid Accuracy: 0.940\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, t_train))\n",
    "dataset_train = dataset_train.repeat()\n",
    "dataset_train = dataset_train.batch(batch_size)\n",
    "flag_true = tf.data.Dataset.from_tensor_slices(tf.ones(len(x_train), dtype=tf.bool))\n",
    "flag_true = flag_true.repeat()\n",
    "dataset_train = tf.data.Dataset.zip((dataset_train, flag_true))\n",
    "\n",
    "dataset_valid = tf.data.Dataset.from_tensor_slices((x_valid, t_valid))\n",
    "dataset_valid = dataset_valid.batch(batch_size)\n",
    "flag_false = tf.data.Dataset.from_tensor_slices(tf.zeros(len(x_valid), dtype=tf.bool))\n",
    "dataset_valid = tf.data.Dataset.zip((dataset_valid, flag_false))\n",
    "\n",
    "handle = tf.placeholder(tf.string)\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    string_handle=handle,\n",
    "    output_types=dataset_train.output_types,\n",
    "    output_shapes=dataset_train.output_shapes\n",
    ")\n",
    "\n",
    "iterator_train = dataset_train.make_one_shot_iterator()\n",
    "iterator_valid = dataset_valid.make_initializable_iterator()\n",
    "\n",
    "(x, t), is_training = iterator.get_next()\n",
    "\n",
    "layers = [\n",
    "    Dense(784, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 10, tf.nn.softmax)\n",
    "]\n",
    "\n",
    "def get_params(layers):\n",
    "    params_all = []\n",
    "    for layer in layers:\n",
    "        params = layer.params\n",
    "        params_all += params\n",
    "    return params_all\n",
    "\n",
    "def f_props(layers, h):\n",
    "    for layer in layers:\n",
    "        h = layer(h)\n",
    "    return h\n",
    "\n",
    "y = f_props(layers, x)\n",
    "params_all = get_params(layers)\n",
    "l2_reg = compute_l2_reg(params_all)\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1)) + lmd * l2_reg\n",
    "\n",
    "updates = sgd(cost, params_all, eta)\n",
    "train = tf.group(*updates)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    handle_train = sess.run(iterator_train.string_handle())\n",
    "    handle_valid = sess.run(iterator_valid.string_handle())\n",
    "    \n",
    "    for i in range(10000):\n",
    "        # Train\n",
    "        sess.run(train, feed_dict={handle: handle_train})\n",
    "        \n",
    "        # Valid\n",
    "        if (i + 1) % 2000 == 0:\n",
    "            sess.run(iterator_valid.initializer)\n",
    "            costs_valid = []\n",
    "            y_preds = []\n",
    "            while True:\n",
    "                try:\n",
    "                    cost_, y_pred = sess.run([cost, y], feed_dict={handle: handle_valid})\n",
    "                    costs_valid.append(cost_)\n",
    "                    y_preds.extend(y_pred.argmax(axis=1))\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "            print('Iteration: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "                i + 1,\n",
    "                np.mean(costs_valid),\n",
    "                accuracy_score(t_valid.argmax(axis=1), y_preds)\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
