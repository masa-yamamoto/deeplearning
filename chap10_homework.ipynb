{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. 変分オートエンコーダ（VAE）でFasionMNISTの画像を生成せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変分オートエンコーダ（VAE）により, FashionMNISTの画像を生成してみましょう.。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ルール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 訓練データはx_train、テストデータはx_testで与えられます。\n",
    "- 下のセルで指定されているx_train以外の学習データは使わないでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLL（負の対数尤度） 235"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提出方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2つのファイルを提出していただきます。\n",
    "    1. テストデータ（x_test）について、VAEで生成した画像をcsvファイル（ファイル名：submission.csv）として保存し（1画像が1行に対応）、**Homeworkタブからchap10を選択して**提出してください。\n",
    "    2. それに対応するpythonのコードをsubmission_code.pyとして保存し、**Homeworkタブからchap10 (code)を選択して**提出してください。 \n",
    "      - セルに書いたコードを.py形式で保存するためには%%writefileコマンドなどを利用してください（writefileコマンドではファイルの保存のみが行われセル内のpythonコード自体は実行されません。そのため、実際にコードを走らせる際にはwritefileコマンドをコメントアウトしてください）。\n",
    "- なお、採点は1で行い、2はコードの確認用として利用します（成績優秀者はコード内容を公開させていただくかもしれません）。コードの内容を変更した場合は、**1と2の両方を提出し直してください**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価について"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 評価は生成画像のテストデータに対するNLL（負の対数尤度）で行います.  $-\\sum_{i=1}^D x_i\\log \\hat{x}_i + (1-x_i)\\log (1-\\hat{x}_i)$\n",
    "- 毎日夜24時にテストデータの一部に対するNLLでLeader Boardを更新します。\n",
    "- 締切日の夜24時にテストデータ全体に対するNLLでLeader Boardを更新します。これを最終的な評価とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サンプルコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 次のセルで指定されているx_trainのみを使って学習させてください.\n",
    "- submission.csvの出力場所は適宜変更してください."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このデータの読み込み部分は修正しないでください\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_mnist():\n",
    "\n",
    "    # 学習データ\n",
    "    x_train = np.load('/root/userspace/public/chap10/data/x_train.npy')\n",
    "    \n",
    "    # テストデータ\n",
    "    x_test = np.load('/root/userspace/public/chap10/data/x_test.npy')\n",
    "\n",
    "    x_train = (x_train.reshape(-1, 784) / 255).astype(np.float32)\n",
    "    x_test = (x_test.reshape(-1, 784) / 255).astype(np.float32)\n",
    "\n",
    "    return (x_train, x_test)\n",
    "\n",
    "x_train, x_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAEの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:1, Train Lower Bound:-282.338257, (-10.305874, -272.032379), Valid Lower Bound:-244.587112\n",
      "EPOCH:2, Train Lower Bound:-253.468246, (-11.575931, -241.892319), Valid Lower Bound:-237.206589\n",
      "EPOCH:3, Train Lower Bound:-249.125122, (-11.994110, -237.131012), Valid Lower Bound:-234.741486\n",
      "EPOCH:4, Train Lower Bound:-246.956818, (-12.170147, -234.786667), Valid Lower Bound:-232.759689\n",
      "EPOCH:5, Train Lower Bound:-245.535858, (-12.270274, -233.265579), Valid Lower Bound:-232.071609\n",
      "EPOCH:6, Train Lower Bound:-244.508667, (-12.377619, -232.131042), Valid Lower Bound:-230.356216\n",
      "EPOCH:7, Train Lower Bound:-243.702499, (-12.447305, -231.255188), Valid Lower Bound:-229.427643\n",
      "EPOCH:8, Train Lower Bound:-243.132156, (-12.516734, -230.615417), Valid Lower Bound:-229.609695\n",
      "EPOCH:9, Train Lower Bound:-242.582382, (-12.531636, -230.050751), Valid Lower Bound:-228.048294\n",
      "EPOCH:10, Train Lower Bound:-242.185364, (-12.581368, -229.603989), Valid Lower Bound:-227.918427\n",
      "EPOCH:11, Train Lower Bound:-241.779266, (-12.621915, -229.157349), Valid Lower Bound:-227.279510\n",
      "EPOCH:12, Train Lower Bound:-241.482666, (-12.661101, -228.821564), Valid Lower Bound:-227.255661\n",
      "EPOCH:13, Train Lower Bound:-241.296082, (-12.684518, -228.611557), Valid Lower Bound:-228.079620\n",
      "EPOCH:14, Train Lower Bound:-240.988525, (-12.713786, -228.274734), Valid Lower Bound:-227.450470\n",
      "EPOCH:15, Train Lower Bound:-240.762558, (-12.725133, -228.037430), Valid Lower Bound:-227.059265\n",
      "EPOCH:16, Train Lower Bound:-240.614853, (-12.744359, -227.870499), Valid Lower Bound:-226.721924\n",
      "EPOCH:17, Train Lower Bound:-240.363754, (-12.762450, -227.601303), Valid Lower Bound:-227.384933\n",
      "EPOCH:18, Train Lower Bound:-240.160248, (-12.781444, -227.378799), Valid Lower Bound:-225.948654\n",
      "EPOCH:19, Train Lower Bound:-240.081360, (-12.797814, -227.283539), Valid Lower Bound:-226.322998\n",
      "EPOCH:20, Train Lower Bound:-239.901245, (-12.821339, -227.079910), Valid Lower Bound:-226.337067\n"
     ]
    }
   ],
   "source": [
    "#%%writefile /root/userspace/chap10/submission_code.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#乱数について追加\n",
    "random_seed = 10 #1~10で10が一番\n",
    "np.random.seed(random_seed)\n",
    "tf.set_random_seed(random_seed) \n",
    "\n",
    "# rng = np.random.RandomState(1234)\n",
    "\n",
    "### define layers ###\n",
    "tf.reset_default_graph()\n",
    "z_dim = 10 #5とかよかったけど。defalutは10\n",
    "\n",
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
    "\n",
    "def encoder(x):# WRITE ME\n",
    "    with tf.variable_scope('Encoder', reuse=tf.AUTO_REUSE):\n",
    "        h1 = tf.layers.Dense(units=200, activation=tf.nn.relu)(x)\n",
    "        h2 = tf.layers.Dense(units=200, activation=tf.nn.relu)(h1)\n",
    "        mean = tf.layers.Dense(units=z_dim)(h2)\n",
    "        var = tf.layers.Dense(units=z_dim, activation=tf.nn.softplus)(h2)\n",
    "    return mean, var    \n",
    "\n",
    "def sampling_z(mean, var):# WRITE ME\n",
    "    epsilon = tf.random_normal(shape=tf.shape(mean))\n",
    "    z = mean + tf.sqrt(var) * epsilon\n",
    "    return z    \n",
    "\n",
    "def decoder(z):# WRITE ME\n",
    "    with tf.variable_scope('Decoder', reuse=tf.AUTO_REUSE):\n",
    "        h3 = tf.layers.Dense(units=200, activation=tf.nn.relu)(z)\n",
    "        h4 = tf.layers.Dense(units=200, activation=tf.nn.relu)(h3)\n",
    "        y = tf.layers.Dense(units=784, activation=tf.nn.sigmoid)(h4)\n",
    "    return y    \n",
    "\n",
    "def lower_bound(x):\n",
    "    #Encode\n",
    "    mean, var = encoder(x)\n",
    "    KL = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + tf_log(var) - mean**2 - var, axis=1))\n",
    "    #Z\n",
    "    z = sampling_z(mean, var)\n",
    "    #Decode\n",
    "    y = decoder(z)\n",
    "    reconstruction = tf.reduce_mean(tf.reduce_sum(x * tf_log(y) + (1 - x) * tf_log(1 - y), axis=1))\n",
    "    \n",
    "    lower_bound = [-KL, reconstruction]\n",
    "    return lower_bound\n",
    "\n",
    "# zcaとかBatchNormを導入しようとしたが、やりかたわからず\n",
    "    \n",
    "### training ###\n",
    "#学習データと検証データに分割\n",
    "x_train, x_valid = train_test_split(x_train, test_size=0.1)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "lower_bound = lower_bound(x)\n",
    "\n",
    "cost = -tf.reduce_sum(lower_bound)\n",
    "\n",
    "# optimizer = tf.train.AdamOptimizer()\n",
    "# train = optimizer.minimize(cost)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "grads = optimizer.compute_gradients(cost)\n",
    "clipped_grads = [(tf.clip_by_value(grad_val, -1., 1.), var) for grad_val, var in grads]\n",
    "train = optimizer.apply_gradients(clipped_grads)\n",
    "\n",
    "valid = tf.reduce_sum(lower_bound)\n",
    "\n",
    "batch_size =100\n",
    "\n",
    "n_batches = x_train.shape[0] // batch_size\n",
    "n_epochs = 20\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for epoch in range(n_epochs):# WRITE ME\n",
    "    rng.shuffle(x_train)\n",
    "    lower_bound_all = []\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        _, lowerbound = sess.run([train, lower_bound], feed_dict={x: x_train[start:end]})\n",
    "        lower_bound_all.append(lowerbound)\n",
    "    lower_bound_all = np.mean(lower_bound_all, axis=0)\n",
    "    lower_bound_valid = sess.run(valid, feed_dict={x: x_valid[0:100]})\n",
    "    print('EPOCH:%d, Train Lower Bound:%lf, (%lf, %lf), Valid Lower Bound:%lf' %\n",
    "          (epoch+1, np.sum(lower_bound_all), lower_bound_all[0], lower_bound_all[1], lower_bound_valid))    \n",
    "    \n",
    "### sampling ###\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "sample_z_func = encoder(x)\n",
    "\n",
    "z = tf.placeholder(tf.float32, [None, z_dim])\n",
    "sample_x_func = decoder(z)\n",
    "\n",
    "# Encode\n",
    "mean, var = sess.run(sample_z_func, feed_dict={x: x_test})\n",
    "sample_z = mean\n",
    "\n",
    "# Decode\n",
    "sample_x = sess.run(sample_x_func, feed_dict={z: sample_z})\n",
    "\n",
    "\n",
    "### to_csv ###\n",
    "with open('/root/userspace/chap10/materials/submission.csv', 'w') as file:\n",
    "    writer = csv.writer(file, lineterminator='\\n')\n",
    "    writer.writerows(sample_x.reshape(-1, 28*28).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
